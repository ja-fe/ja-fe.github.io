[
  {
    "objectID": "research/research_landingpage.html",
    "href": "research/research_landingpage.html",
    "title": "Research",
    "section": "",
    "text": "I primarily work on Synthetic Aperture RADAR remote sensing of cryospheric systems, but my work also touches on other remote sensing methods, thermodynamic models which ingest RS data, and physics pedagogy.",
    "crumbs": [
      "Research",
      "Research Home"
    ]
  },
  {
    "objectID": "research/remote_sensing/SAR_research.html",
    "href": "research/remote_sensing/SAR_research.html",
    "title": "SAR Research",
    "section": "",
    "text": "Synthetic Aperture RADAR data is useful in monitoring cryospheric systems – to be updated soon!",
    "crumbs": [
      "Research",
      "Remote Sensing",
      "SAR Research"
    ]
  },
  {
    "objectID": "outreach/outreach_landingpage.html",
    "href": "outreach/outreach_landingpage.html",
    "title": "Outreach",
    "section": "",
    "text": "Simply because I’m chronically online doesn’t mean I don’t engage with other humans, and these presentations and workshops are proof!",
    "crumbs": [
      "Outreach",
      "Outreach Home"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "misc/funandgames/obtuseunits.html",
    "href": "misc/funandgames/obtuseunits.html",
    "title": "Obtuse Units",
    "section": "",
    "text": "TODO: This doesn’t work yet, because it uses Python on a static site and static Shiny is still being made (easily) operational with Quarto. And I don’t want to create a Shiny server just for this project. Check out the obtuse-conversion repo on my Github if you want to have fun with a program that turns arbitrary text containing units into absurd but accurate jumbles of SI units, e.g. “I just ran 5 miles!” –&gt; “I just ran 804634695 petacoulomb-attowebers per hectonewton-second!”",
    "crumbs": [
      "-misc-",
      "Fun and Games",
      "Obtuse Units"
    ]
  },
  {
    "objectID": "misc/misc_landingpage.html",
    "href": "misc/misc_landingpage.html",
    "title": "miscellaneous",
    "section": "",
    "text": "Less than strictly academic works lie ’neath these tabs, abandon scope all ye who enter.",
    "crumbs": [
      "-misc-",
      "misc"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "jf_web",
    "section": "",
    "text": "Welcome!\nEverything on this website was built and programmed by me, some of it even in languages and libraries I understand! However, it would not have been possible without the immense body of literature and work made freely available by countless people all over the world. In that spirit, the entire code for this website is freely available here.\nSee below some choice interactive course notes – check out the Teaching tab for more."
  },
  {
    "objectID": "index.html#speckle-as-a-wave-interference-phenomenon",
    "href": "index.html#speckle-as-a-wave-interference-phenomenon",
    "title": "jf_web",
    "section": "Speckle as a wave interference phenomenon",
    "text": "Speckle as a wave interference phenomenon\nLet’s look an illustrative real-world manifestation of this conceptual framework. SAR images are subject to speckle, a type of image distortion or noise which affects pixels in a stochastic, multiplicative way. Why does this occur?\nConsider that the returned wave associated with a given pixel likely isn’t the result of a single interation with a single pointwise object. If multiple reflectors (or similarly, a continuous reflector) lie within the pixel, then the returned wave is the sum of multiple individual waves.\nLet’s imagine we have a pixel with two identical point reflectors lying within it. How does the returned wave change as a function of where those reflectors are located? Move the blue and red targets in the pixel below:\n\nCode\nchart = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    // define a bounding rectangle\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", height - 2*stroke_width)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 0.087124976) //This is a hard-coded value based on the prescribed physical parameters. It's hardcoded because it's easier than dealing with the resulting reactive dependencies since this cell should never be run again\n\n    // define data used for circles\n    const circles = d3.range(2).map(i =&gt; ({\n        x: (i+2) * width / 5,\n        y: (i+1) * height / 3,\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", d =&gt; d.x)\n            .attr(\"cy\", d =&gt; d.y)\n            .attr(\"r\", radius)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[d.index * 3])\n            .attr(\"id\", function(d,i) {return i})\n            .call(drag)\n\n    return svg.node();\n}\nchart2 = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    //define a function to take the canvas position of the leftside chart to the\n    //  corresponding region in the second chart\n    //  it's messy because I solved the system by hand and didn't simplify, RIP\n    //  to future Jake if I ever have to un-hardcode the object position values\n    function lineartransform(xposition){\n        return (2*height/5 - radius)/(5/7*width -2*radius-2)*xposition + width/7 + 2/5*height + radius/2 - (2*height/5 - radius)*(width/7+radius+1)/(5/7*width-2*radius-2)\n    }\n\n    // define a earth curvature line\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", height - 2*stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", stroke_width/2)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 0)\n\n    // define lines going from the target to the satellites (first, so they appear under them)\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 3*height/20)\n        .attr(\"x2\", lineartransform(x1))\n        .attr(\"y1\", 3*height/20)\n        .attr(\"y2\", height - 2*stroke_width)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"blue\")\n\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 3*height/20)\n        .attr(\"x2\", lineartransform(x2))\n        .attr(\"y1\", 3*height/20)\n        .attr(\"y2\", height - 2*stroke_width)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"red\")\n\n\n    // define a rectangle representing the satellite\n    svg.append(\"rect\")\n        .attr(\"x\", width/7 + height/10)\n        .attr(\"y\", height/10)\n        .attr(\"width\", height/10)\n        .attr(\"height\", height/10)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", .50)\n    \n    // define notches indicating the bounds of the pixel\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 2*height/5)\n        .attr(\"x2\", width/7 + 2*height/5)\n        .attr(\"y1\", height - 2*stroke_width)\n        .attr(\"y2\", height - 2*stroke_width - height/20)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"black\")\n\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 4*height/5)\n        .attr(\"x2\", width/7 + 4*height/5)\n        .attr(\"y1\", height - 2*stroke_width)\n        .attr(\"y2\", height - 2*stroke_width - height/20)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"black\")\n\n    // define data used for circles\n    const circles = d3.range(2).map(i =&gt; ({\n        x: (i+2) * width / 5,\n        y: (i+1) * height / 3,\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", function(d,i) {\n                if (i == 0) {return lineartransform(x1)}\n                else {return lineartransform(x2)}\n            })\n            .attr(\"cy\", height - 2*stroke_width)\n            .attr(\"r\", radius/2)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[d.index * 3])\n            .attr(\"id\", function(d,i) {return i})\n\n    // add text\n    svg.append(\"text\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", .94*height)\n        .style(\"font-size\", \"28px\")\n        .text(\"side view\")\n\n    svg.append(\"text\")\n        .attr(\"x\", width/2)\n        .attr(\"y\", .15*height)\n        .style(\"font-size\", \"24px\")\n        .style(\"font-style\", \"italic\")\n        .text(\"*wildly not to scale\")\n\n    return svg.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nformatted_d1 = (0.5*distance_travelled_w1).toFixed(2).replace(/\\B(?&lt;!\\.\\d*)(?=(\\d{3})+(?!\\d))/g, \",\");\nformatted_d2 = (0.5*distance_travelled_w2).toFixed(2).replace(/\\B(?&lt;!\\.\\d*)(?=(\\d{3})+(?!\\d))/g, \",\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistance from target one to the satellite: m\nDistance from target two to the satellite: m\n\n\n\nCode\n// defines how circles change appearance and position in response to cursor drag\ndrag = {\n\n    // move the circles to cursor position when dragging is active\n    function dragged(event, d){\n        var newx = event.x;\n        if (newx &lt; xbounds[0]) newx = xbounds[0];\n        if (newx &gt; xbounds[1]) newx = xbounds[1];\n        var newy = event.y;\n        if (newy &lt; ybounds[0]) newy = ybounds[0];\n        if (newy &gt; ybounds[1]) newy = ybounds[1];\n        \n        if (d3.select(this).attr('id') == \"0\") {\n            mutable x1 = newx;\n            mutable y1 = newy;\n        }\n        if (d3.select(this).attr('id') == \"1\") {\n            mutable x2 = newx;\n            mutable y2 = newy;\n        }\n        \n        d3.select(this).raise().attr(\"cx\", d.x = newx).attr(\"cy\", d.y = newy);\n\n        var dt1 = 2*Math.sqrt(sat_z**2 + (mutable x1/width*pixel_width - sat_x)**2 + (mutable y1/width*pixel_width - sat_y)**2);\n        var dt2 = 2*Math.sqrt(sat_z**2 + (mutable x2/width*pixel_width - sat_x)**2 + (mutable y2/width*pixel_width - sat_y)**2);\n        var p1  =  dt1 / wavelength *2 *Math.PI;\n        var p2  =  dt2 / wavelength *2 *Math.PI;\n\n        d3.select(\"rect\").attr(\"fill-opacity\", 1-Math.abs(Math.cos((p1-p2)/2)));\n        //d3.select(\"text\").text(1-Math.abs(Math.cos((p1-p2)/2))).style(\"fill\",\"darkOrange\");\n    }\n\n    // map the d3 drag event functionality to these custom functions\n    return d3.drag()\n        .on(\"drag\", dragged)\n}\n\n\n\n\n\n\n\n\n\nCode\nmutable x1= 2*width/5;\nmutable y1= height/3;\nmutable x2= 3*width/5;\nmutable y2= 2*height/3;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nstroke_width = 7;\nwidth = 700;\nheight = 500 + 2*stroke_width;\nradius = 25;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nxbounds = [width/7 + radius + 1, 6*width/7 - radius - 1]\nybounds = [ radius + 1  + stroke_width, height - radius - 1 - stroke_width]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndistance = 4;\nNumPoints = 1000;\nwavelength = .5;\namplitude = 15;\nspeed = 10;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n// display variables\nxscale_factor = 100;\n\n\n\n\n\n\n\n\n\nCode\nsat_x = -100000;\nsat_y = 100000;\nsat_z = 600000;\npixel_width = 3;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndistance_travelled_w1 = 2*Math.sqrt(sat_z**2 + (x1/width*pixel_width - sat_x)**2 + (y1/width*pixel_width - sat_y)**2);\ndistance_travelled_w2 = 2*Math.sqrt(sat_z**2 + (x2/width*pixel_width - sat_x)**2 + (y2/width*pixel_width - sat_y)**2);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nphase_w1 = distance_travelled_w1 / wavelength *2 *Math.PI;\nphase_w2 = distance_travelled_w2 / wavelength *2 *Math.PI;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwave1 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j*xscale_factor, amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w2)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwave2 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j*xscale_factor , amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w1)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwaveSum = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j*xscale_factor , amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w1) + amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w2)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\ntime = {\n  let i = 0;\n  while (true) {\n    i += speed * 0.01;\n    yield i\n  }\n}\n\n\n\n\n\n\n\n\n\nCode\nr = d3.line()(wave1);\nb = d3.line()(wave2);\nsvg`&lt;svg viewBox=\"0 -32 400 64\"&gt;\n  &lt;path d=\"${r}\" stroke=\"red\" fill=\"none\" /&gt;\n  &lt;path d=\"${b}\" stroke=\"blue\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np = d3.line()(waveSum);\nsvg`&lt;svg viewBox=\"0 -64 400 130\"&gt;\n  &lt;path d=\"${p}\" stroke=\"black\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nd3 = require(\"d3@7\")\n\n\n\n\n\n\n\nHere we’ve considered a SAR satellite 600km above Earth, emitting 50cm wavelength radiation with a pixel resolution of 3m.\nThe distance from each target to the satellite affects where in their cycle each wave is re-intercepted, and thus the difference determines whether those returned waves interfere constructively or deconstructively. Thus a random distribution of targets creates a random difference in distance to the satellite, creating a random level of interference in each pixel. This means the intensity of each pixel is randomly (though not necessarily uniformly) multiplied by a value from 0 (perfect deconstructive interference) to 1 (perfect constructive interference). This is the origin of speckle, and reason why it manifests as multiplicative noise (as opposed to additive).\nLet’s now consider two pixels: one with more, stronger scatterers and one with fewer, weaker scatterers – perhaps pixel one belongs to some dense shrubland, while the other is a freshly plowed field. The distribution of scatterers is likely quite random – what happens to the brightness of these pixels under different configurations?\n\n\nCode\ntargetnum_1 = 10;\ntargetnum_2 = 10;\nmax_radius_p1 = 35;\nmin_radius_p1 = 25;\nmax_radius_p2 = 20;\nmin_radius_p2 = 15;\n\nradii_p1 = {\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_1; i++) {\n            data.push(Math.random()*(max_radius_p1-min_radius_p1) + min_radius_p1);\n        }\n    return data;\n}\n\nradii_p2 = {\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_2; i++) {\n            data.push(Math.random()*(max_radius_p2-min_radius_p2) + min_radius_p2);\n        }\n    return data;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof reroll_toggle = Inputs.form(\n    [\n        Inputs.button(\"Redistribute Targets\"),\n        Inputs.button(\"Auto Redistribute Targets\"),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    })\n\nvtoggle1    = reroll_toggle[0];\nauto_toggle = reroll_toggle[1];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntime_auto = {\n  let i = 0;\n  while (auto_toggle%2==1) {\n    i += 1;\n    yield i\n  }\n}\n\n\n\n\n\n\n\n\n\nCode\npixel1_positions = {\n    var dummy  = vtoggle1;\n    var dummy2 = time_auto;\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_1; i++) {\n            var x = Math.random()*(5*width/7 - 2*max_radius_p1) + max_radius_p1 + width/7;\n            var y = Math.random()*(height - 2*max_radius_p1) + max_radius_p1;\n            data.push([x,y]);\n        }\n    return data\n}\n\npixel2_positions = {\n    var dummy  = vtoggle1;\n    var dummy2 = time_auto;\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_2; i++) {\n            var x = Math.random()*(5*width/7 - 2*max_radius_p1) + max_radius_p1 + width/7;\n            var y = Math.random()*(height - 2*max_radius_p1) + max_radius_p1;\n            data.push([x,y]);\n        }\n    return data\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n//two pixels with targets in them\n\nchart3 = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    // define a bounding rectangle\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", height - 2*stroke_width)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 1-amplitude_p1/200)\n\n    // define data used for circles\n    const circles = d3.range(targetnum_1).map(i =&gt; ({\n        x: pixel1_positions[i][0],\n        y: pixel1_positions[i][1],\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", d =&gt; d.x)\n            .attr(\"cy\", d =&gt; d.y)\n            .attr(\"r\", function(d,i) {return radii_p1[i]})\n            .attr(\"stroke\", \"black\")\n            .attr(\"stroke-width\", 4)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[0])\n            .attr(\"id\", function(d,i) {return i})\n\n    return svg.node();\n}\nchart4 = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    // define a bounding rectangle\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", height - 2*stroke_width)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 1-amplitude_p2/200)\n\n    // define data used for circles\n    const circles = d3.range(targetnum_2).map(i =&gt; ({\n        x: pixel2_positions[i][0],\n        y: pixel2_positions[i][1],\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", d =&gt; d.x)\n            .attr(\"cy\", d =&gt; d.y)\n            .attr(\"r\", function(d,i) {return radii_p2[i]})\n            .attr(\"stroke\", \"black\")\n            .attr(\"stroke-width\", 4)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[0])\n            .attr(\"id\", function(d,i) {return i})\n\n    return svg.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n    round: true,\n    color: {legend: true},\n    x: {label: \"Brightness\"},\n    y: {label: \"Frequency\"},\n    marks: [\n        Plot.rectY(brightnesses, Plot.binX({y2: \"count\"}, {x: \"x\", fill: \"p\", mixBlendMode: \"multiply\"})),\n        Plot.ruleY([0])\n        ]\n})\n\n\n\n\n\n\n\n\n\nCode\namplitude_p1 = {\n\n    var dummy = vtoggle1;\n    \n    var amplitude_naught = radii_p1[0];\n\n    var dt_naught =\n        2*Math.sqrt(\n            sat_z**2\n            + (pixel1_positions[0][0]/width*pixel_width - sat_x)**2\n            + (pixel1_positions[0][1]/width*pixel_width - sat_y)**2\n        );\n    \n    var phase_naught =\n        dt_naught / wavelength *2 *Math.PI;\n    \n    //successively add the waves, determining the new phases and amplitudes\n    for (var i = 1; i &lt;= targetnum_1-1; i++) {\n        //compute the phase of the next subwave\n        var dt_next =\n            2*Math.sqrt(\n                sat_z**2\n                + (pixel1_positions[i][0]/width*pixel_width - sat_x)**2\n                + (pixel1_positions[i][1]/width*pixel_width - sat_y)**2\n        );\n\n        var phase_next = \n            dt_next / wavelength *2 *Math.PI;\n        \n        //compute the amplitude of the new sum\n        var new_amplitude =\n            Math.sqrt(\n                amplitude_naught**2\n                + radii_p1[i]**2\n                + 2*amplitude_naught*radii_p1[i]*Math.cos(phase_next-phase_naught)\n            );\n\n        //compute the phase of the new sum\n        var new_phase =\n            Math.atan(\n                (amplitude_naught*Math.sin(phase_naught) + radii_p1[i]*Math.sin(phase_next))\n                /(amplitude_naught*Math.cos(phase_naught) + radii_p1[i]*Math.cos(phase_next))\n            )\n\n        amplitude_naught = new_amplitude;\n        phase_naught = new_phase;\n\n    }\n    return amplitude_naught\n}\n\namplitude_p2 = {\n\n    var dummy = vtoggle1;\n    \n    var amplitude_naught = radii_p2[0];\n\n    var dt_naught =\n        2*Math.sqrt(\n            sat_z**2\n            + (pixel2_positions[0][0]/width*pixel_width - sat_x)**2\n            + (pixel2_positions[0][1]/width*pixel_width - sat_y)**2\n        );\n    \n    var phase_naught =\n        dt_naught / wavelength *2 *Math.PI;\n    \n    //successively add the waves, determining the new phases and amplitudes\n    for (var i = 1; i &lt;= targetnum_1-1; i++) {\n        //compute the phase of the next subwave\n        var dt_next =\n            2*Math.sqrt(\n                sat_z**2\n                + (pixel2_positions[i][0]/width*pixel_width - sat_x)**2\n                + (pixel2_positions[i][1]/width*pixel_width - sat_y)**2\n        );\n\n        var phase_next = \n            dt_next / wavelength *2 *Math.PI;\n        \n        //compute the amplitude of the new sum\n        var new_amplitude =\n            Math.sqrt(\n                amplitude_naught**2\n                + radii_p2[i]**2\n                + 2*amplitude_naught*radii_p2[i]*Math.cos(phase_next-phase_naught)\n            );\n\n        //compute the phase of the new sum\n        var new_phase =\n            Math.atan(\n                (amplitude_naught*Math.sin(phase_naught) + radii_p2[i]*Math.sin(phase_next))\n                /(amplitude_naught*Math.cos(phase_naught) + radii_p2[i]*Math.cos(phase_next))\n            )\n\n        amplitude_naught = new_amplitude;\n        phase_naught = new_phase;\n\n    }\n    return amplitude_naught\n}\n\n{\nmutable brightnesses.push({x: amplitude_p1, p: \"Pixel 1\"});\nmutable brightnesses.push({x: amplitude_p2, p: \"Pixel 2\"});\nmutable brightnesses = mutable brightnesses;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n//histogram to be populated with the brightness values of the two pixels\nmutable brightnesses = [];\n\n\n\n\n\n\n\nClicking through a few dozen random configurations of each pixel, we can see in the developing histogram of their brightnesses that while the pixel with more strongly reflecting targets is on average brighter, there are many times when the pixel with weaker targets actually gives a higher return. This is due to the random level of interference we’ve called speckle. We can exploit the fact that the average value remains higher to identify likely high-return areas in speckle filtering. As an aside, notice that the distributions of brightness appear relatively Gaussian – this is a lovely invocation of the Central Limit Theorem."
  },
  {
    "objectID": "teaching/coherence_and_polarization/getting_incoherent.html",
    "href": "teaching/coherence_and_polarization/getting_incoherent.html",
    "title": "Getting Incoherent",
    "section": "",
    "text": "But that’s just two “pure” waves – what happens when EMR is the sum of many waves of different frequencies? Try adding more and more waves of different frequencies, uniformly distributed in a small range (or band): \n\n\nCode\nviewof form_m2_1 = Inputs.form(\n    [\n        Inputs.range([1, 10], {label: \"# of Waves\", step: 1, value: 1}),\n        Inputs.range([1, 20], {label: \"Speed\", step: 1, value: 10})\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\nNumWaves_m2 = form_m2_1[0];\nspeed_m2    = form_m2_1[1];\n\namplitude_m2 = 6;\ndistance_m2 = 400;\nNumPoints_m2 = 1000;\nwavelengths_m2 = [30,29,25,33,36,24,28,35,40,22,37];\nphases_m2 = [0,0,1,0.5,2,3.1,4,4.9,1.3,.8,6];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwaveSum_m2 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints_m2; i++) {\n        var y = 0\n        for (var k = 1; k &lt;= NumWaves_m2; k++) {\n            var j = i * distance_m2 / NumPoints_m2;\n            y += amplitude_m2 * Math.sin(j * 2*Math.PI / wavelengths_m2[k] + time_m2 + phases_m2[k])\n        }\n        data.push([j,y]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwaves_m2 = {\n    var waves = []\n    for (var i = 1; i &lt;= wavelengths_m2.length; i++) {\n        var data = [];\n        for (var k = 1; k &lt;= NumPoints_m2; k++) {\n            var j = k * distance_m2 / NumPoints_m2;\n            data.push([j , amplitude_m2* Math.sin(j * 2*Math.PI / wavelengths_m2[i] + time_m2 + phases_m2[i]) + amplitude_m2*2.4*(i+2)]);\n        }\n        waves.push(data)\n    }\n    return waves;\n}\n\n\n\n\n\n\n\n\n\nCode\ntime_m2 = {\n  let i = 0;\n  while (true) {\n    i += speed_m2 * 0.01;\n    yield i\n  }\n}\n\n\n\n\n\n\n\n\n\nCode\ncolors_m2 = {\n    var colors = []\n    for (var i = 0; i &lt; wavelengths_m2.length; i++){\n        if (i &lt; NumWaves_m2){colors.push(\"red\")}\n        else {colors.push(\"white\")}\n    }\n    return colors\n}\n\nsummed_wave_m2 = d3.line()(waveSum_m2);\nw_m2 = d3.line()(waves_m2[0]);\nsvg`&lt;svg viewBox=\"0 -50 400 250\"&gt;\n  &lt;path d=\"${summed_wave_m2}\" stroke=\"black\" fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[0])}\" stroke=${colors_m2[0]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[1])}\" stroke=${colors_m2[1]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[2])}\" stroke=${colors_m2[2]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[3])}\" stroke=${colors_m2[3]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[4])}\" stroke=${colors_m2[4]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[5])}\" stroke=${colors_m2[5]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[6])}\" stroke=${colors_m2[6]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[7])}\" stroke=${colors_m2[7]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[8])}\" stroke=${colors_m2[8]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[9])}\" stroke=${colors_m2[9]} fill=\"none\" /&gt;\n  &lt;path d=\"${d3.line()(waves_m2[10])}\" stroke=${colors_m2[10]} fill=\"none\" /&gt;\n&lt;/svg&gt;`",
    "crumbs": [
      "Teaching",
      "Wave Coherence and Polarization State",
      "Getting Incoherent"
    ]
  },
  {
    "objectID": "teaching/coherence_and_polarization/polarization_state_pure.html",
    "href": "teaching/coherence_and_polarization/polarization_state_pure.html",
    "title": "Polarization State (Pure)",
    "section": "",
    "text": "Use the sliders below to explore polarization state as expressed in a linear basis (e.g. V/H)\n\n\nCode\nviewof form1 = Inputs.form(\n    [\n        Inputs.range([0, 20], {label: \"Amplitude 1\",    step: 1, value: 10}),\n        Inputs.range([0, 20], {label: \"Amplitude 2\", step: 1, value: 10}),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\namplitude_1 = form1[0];\namplitude_2 = form1[1];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof form2 = Inputs.form(\n    [\n        Inputs.range([0, 6.2], {label: \"Phase Diff\", step: 0.1, value: 0})\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\nphase_diff  = form2[0];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof form3 = Inputs.form(\n    [\n        Inputs.button(\"Toggle Sum\"),\n        Inputs.button(\"Toggle H and V\")\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\nvtoggle1    = form3[0];\nvtoggle2    = form3[1];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nl1_color = {return 0xff0000}\nl2_color = {return 0x0000ff}\nl3_color = {return 0x36454f}\n\nrender_l1l2 = {\n    if(vtoggle2 % 2 == 0){return true}\n        else{return false}\n}\n\nrender_l3 = {\n    if(vtoggle1 % 2 == 0){return false}\n        else{return true}\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n{\n    const renderer = new THREE.WebGLRenderer({antialias: true, alpha: true});\n    invalidation.then(() =&gt; renderer.dispose());\n    renderer.setSize(width, height);\n    renderer.setPixelRatio(devicePixelRatio);\n    renderer.setClearColor( 0xffffff, 0 )\n    \n    const controls = new THREE.OrbitControls(camera, renderer.domElement);\n    controls.addEventListener(\"change\", () =&gt; renderer.render(scene, camera));\n    invalidation.then(() =&gt; (controls.dispose(), renderer.dispose()));\n    \n    while (true) {\n        renderer.render(scene, camera);\n        yield renderer.domElement;\n    }\n}\n\n\n\n\n\n\n\n\n\nCode\nscene = {\n  const scene = new THREE.Scene();\n  scene.background = null;\n  if (render_l1l2 == true){\n    scene.add(line1);\n    scene.add(line2);\n  };\n  if (render_l3 == true){\n    scene.add(line3)\n  };\n  return scene;\n}\n\n\n\n\n\n\n\n\n\nCode\nline1 = {\n    const material = new THREE.LineMaterial({\n        color: l1_color,\n        linewidth: 3,\n    });\n\n    material.resolution.set(width, height);\n\n    const points = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        points.push( i-NumPoints/2, 0, 2*amplitude_1*Math.sin(i/10) );\n    }\n\n    const geometry = new THREE.LineGeometry().setPositions( points );\n    const line = new THREE.Line2( geometry, material );\n    return line;\n}\n\nline2 = {\n    const material = new THREE.LineMaterial({\n        color: l2_color,\n        linewidth: 3,\n    });\n\n    material.resolution.set(width, height);\n\n    const points = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        points.push( i-NumPoints/2, 2*amplitude_2*Math.sin(i/10 + phase_diff), 0);\n    }\n\n    const geometry = new THREE.LineGeometry().setPositions( points );\n    const line = new THREE.Line2( geometry, material );\n    return line;\n}\n\nline3 = {\n    const material = new THREE.LineMaterial({\n        color: l3_color,\n        linewidth: 3,\n    });\n\n    material.resolution.set(width, height);\n\n    const points = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        points.push(i-NumPoints/2, 2*amplitude_2*Math.sin(i/10 + phase_diff), 2*amplitude_1*Math.sin(i/10));\n    }\n\n    const geometry = new THREE.LineGeometry().setPositions( points );\n    const line = new THREE.Line2( geometry, material );\n    return line;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncamera = {\n    const camera = new THREE.PerspectiveCamera( 45, window.innerWidth / window.innerHeight, 1, 500 );\n    camera.position.set( 100, 100, 100 );\n    camera.lookAt( 0, 0, 0 );\n    return camera;\n}\n\n\n\n\n\n\n\n\n\nCode\nheight = 600;\nNumPoints = 200;\nNumPoints_ellipse = 200;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nversion=`0.130.0`;\nTHREE = {\n    const THREE = window.THREE = await require(`three@${version}/build/three.min.js`);\n    await require(`three@${version}/examples/js/controls/OrbitControls.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/LineSegments2.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/LineSegmentsGeometry.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/Line2.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/LineGeometry.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/LineMaterial.js`).catch(() =&gt; {});\n\n    return THREE;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooking at this mono-frequency wave head-on, we can see that the electric field vector traces out an ellipse. Each combination of power in the V, power in the H and phase difference corresponds to a unique ellipse. Thus when we think about all the ways a pure wave could be polarization-wise, we can use two equivalent classes of description. Describe the basis waves (Power in the V, power in the H, and their phase difference) or the polarization ellipse (e.g. length of major axis, length of minor axis, angle of orientation).\n\n\nCode\nellipse_points = {\n    var data = [];\n    for (var i = 1; i&lt;=NumPoints_ellipse;i++){\n        data.push([2*amplitude_1*Math.sin(i/10), 2*amplitude_2*Math.sin(i/10 + phase_diff)])\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nellipse = d3.line()(ellipse_points);\nsvg`&lt;svg viewBox=\"-50 -50 100 100\"&gt;\n  &lt;path d=\"${ellipse}\" stroke=\"gray\" fill=\"none\" /&gt;\n&lt;/svg&gt;`",
    "crumbs": [
      "Teaching",
      "Wave Coherence and Polarization State",
      "Polarization State (Pure)"
    ]
  },
  {
    "objectID": "teaching/coherence_and_polarization/visualizing_coherence.html",
    "href": "teaching/coherence_and_polarization/visualizing_coherence.html",
    "title": "Visualizing Coherence",
    "section": "",
    "text": "The waveform is… complex now, to say the least. It might not even be periodic anymore! But how can we concretely define this notion of “coherence”? Technically the wave is well-defined everywhere in space here. Indeed if we knew the underlying ten pure waves, we could know exactly what this ugly wave is doing everywhere in space.\nBut in reality we don’t have the luxury of perfectly measuring the wave at every position for all time. We have to make do with sampling a subset of it. Let’s consider a pure state again, where we measure the value of a portion over time and see how much that information constrains the wave’s behaviour at another position: \n\n\nCode\nviewof form_m3_1 = Inputs.form(\n    [\n        Inputs.range([5, 50], {label: \"Wavelength\",    step: 1, value: 35}),\n        Inputs.range([1, 20], {label: \"Speed\", step: 1, value: 10}),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\nwavelength_m3 = form_m3_1[0];\nspeed_m3      = form_m3_1[1]\n\nviewof form_m3_2 = Inputs.form(\n    [\n        Inputs.range([500, 850], {label: \"Delay\", step: 5, value: 640}),\n        Inputs.button(\"Toggle Wave\")\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\nd5x_m3  = form_m3_2[0];\nvtoggle = form_m3_2[1]\n\n\n\n//viewof wavelength_m3    = Inputs.range([5, 50], {label: \"Wavelength\",    step: 1});\n//viewof speed_m3     = Inputs.range([1, 10], {label: \"Speed\", step: 1});\n//viewof d5x_m3       = Inputs.range([500, 850], {label: \"Delay\", step: 5, value: 640});\n//viewof vtoggle      = Inputs.button(\"Toggle Wave\")\n\nd1x_m3 = 100;\nd2x_m3 = 110;\nd3x_m3 = 120;\nd4x_m3 = 130;\n\nobservation_time = 400;\namplitude_m3 = 25;\n\ndistance = 400;\nNumPoints = 1000;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwave_m3 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j , amplitude_m3 * Math.sin(j * 2*Math.PI / wavelength_m3 + time_m3)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nd1y_m3 = wave_m3[d1x_m3][1];\nd2y_m3 = wave_m3[d2x_m3][1];\nd3y_m3 = wave_m3[d3x_m3][1];\nd4y_m3 = wave_m3[d4x_m3][1];\nd5y_m3 = wave_m3[d5x_m3][1];\nvisible = {\n  if(vtoggle % 2 == 0){return \"black\"}\n  else{return \"white\"}\n  }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntime_m3 = {\n  let i = 0;\n  while (true) {\n    i += speed_m3 * 0.01;\n    yield i\n  }\n}\n\n\n\n\n\n\n\n\n\nCode\nout_m3 = d3.line()(wave_m3);\nsvg`&lt;svg viewBox=\"0 -50 400 85\"&gt;\n  &lt;path d=\"${out_m3}\" stroke=${visible} fill=\"none\" /&gt;\n  &lt;circle cx=${d1x_m3 * distance / NumPoints} cy=${d1y_m3} r=\"2.5\" fill=\"red\"/&gt;\n  &lt;circle cx=${d2x_m3 * distance / NumPoints} cy=${d2y_m3} r=\"2.5\" fill=\"DarkOrange\"/&gt;\n  &lt;circle cx=${d3x_m3 * distance / NumPoints} cy=${d3y_m3} r=\"2.5\" fill=\"DarkOrange\"/&gt;\n  &lt;circle cx=${d4x_m3 * distance / NumPoints} cy=${d4y_m3} r=\"2.5\" fill=\"DarkOrange\"/&gt;\n  &lt;circle cx=${d5x_m3 * distance / NumPoints} cy=${d5y_m3} r=\"2.5\" fill=\"blue\"/&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n//y(t) for the measured point of the wave (red dot)\np1_t = {\n    var p1_t = [];\n    for (var t =1; t &lt;= observation_time; t++){\n        var j = d1x_m3 * distance / NumPoints;\n        var k = t / wavelength_m3;\n        p1_t.push([k,amplitude_m3 * Math.sin(j * 2*Math.PI / wavelength_m3 + k)]);\n    }\n    return p1_t;\n}\n\n\n\n\n\n\n\n\n\nCode\n//y(t) for the hypothetical point of the wave (blue dot)\np2_t = {\n    var p2_t = [];\n    for (var t =1; t &lt;= observation_time; t++){\n        var j = d5x_m3 * distance / NumPoints;\n        var k = t / wavelength_m3;\n        p2_t.push([k,amplitude_m3 * Math.sin(j * 2*Math.PI / wavelength_m3 + k)]);\n    }\n    return p2_t;\n}\n\n\n\n\n\n\n\n\n\nCode\nplot1_m3 ={\n  var p = Plot.plot({\n    height: 200,\n    width: width/2,\n    x: {line: true, label: \"time\", ticks:0, anchor:\"bottom\", labelAnchor: \"center\"},\n    y: {label: \"amplitude\", ticks:0, anchor:\"left\", labelAnchor:\"center\"},\n    fill: \"red\",\n    marks: [\n        Plot.line(p1_t, {stroke:\"red\", strokeWidth:3})\n    ]\n  })\n  p.setAttribute(\"font-size\", 18);\n  return p\n}\n\n\n\n\n\n\n\n\n\nCode\nplot2_m3 = {\n    var p = Plot.plot({\n        height: 200,\n        width: width/2,\n        x: {line: true, label: \"time\", ticks:0, anchor:\"bottom\", labelAnchor: \"center\"},\n        y: {label: \"amplitude\", ticks:0, anchor:\"left\", labelAnchor:\"center\"},\n        stroke: \"blue\",\n        marks: [\n            Plot.line(p2_t, {stroke:\"blue\", strokeWidth:3})\n        ]\n    })\n  p.setAttribute(\"font-size\", 18);\n  return p\n}\n\n\n\n\n\n\n\n\n\nCode\nhtml`&lt;html&gt;\n &lt;head&gt;\n &lt;/head&gt;\n &lt;body&gt;\n    &lt;div class=\"container\" style=\"display: flex; height: 300px;\"&gt;\n        &lt;div style=\"width: 50%;\"&gt;\n            ${plot1_m3}\n        &lt;/div&gt;\n        &lt;div style=\" width: 50%;\"&gt;\n            ${plot2_m3}\n        &lt;/div&gt;\n    &lt;/div&gt;\n &lt;/body&gt;\n&lt;/html&gt;`",
    "crumbs": [
      "Teaching",
      "Wave Coherence and Polarization State",
      "Visualizing Coherence"
    ]
  },
  {
    "objectID": "teaching/SAR_speckle_and_filtering/speckle_filters_adaptive.html",
    "href": "teaching/SAR_speckle_and_filtering/speckle_filters_adaptive.html",
    "title": "Speckle filtering (adaptive)",
    "section": "",
    "text": "A problem with our previous filters was that they apply the same operation to every pixel without any further nuance (i.e. they are static). But perhaps we want a different filter applied to each pixel based on the nature of its local neighbourhood.\nEarlier we may have used a filter like this one:\n\\[\n\\begin{bmatrix}\n    .35 & 45 & .5 & .45 & .35 \\\\\n    .45 & 0.7 & 1 & 0.7 & .45 \\\\\n    .5 & 1 & 5 & 1 & .5 \\\\\n    .45 & 0.7 & 1 & 0.7 & .45 \\\\\n    .35 & .45 & .5 & .45 & .35 \\\\\n\\end{bmatrix}\n\\]\nNotice that this is essentially like holding a ‘vote’ on the new value of the centre pixel. The centre pixel itself has a strong ‘voting power’ of 5, while its closest neighbours have a voting power of 1, the next closest 0.7, and so on until the furthest away pixels have a meager voting power of 0.35. We could say that this filter wants to take an average in order to undo speckle, but ‘trusts’ far away pixels less, since they are probably more likely to belong to a different object than the centre pixel.\nBut this “smarter blur” still leaves us with the problem of pixels near boundaries getting ‘polluted’ by the values of nearby pixels which actually correspond to a different object. We could address this if we had some way of determining if we were probably near an edge. Consider two neighbourhoods, one corresponding to a single object (homogenous, e.g. some open water) and another corresponding to where two objects meet (edge, e.g. where grass becomes road):\n\n\n\n\n\nCode\nhom_neighbourhood = [\n    [57, 44, 25, 43, 87],\n    [58, 83, 50, 49, 35],\n    [12, 43, 15, 34, 31],\n    [10, 59, 45, 70, 150],\n    [32, 70, 84, 6, 46]\n];\nimshow(hom_neighbourhood, 40, d3.interpolateGreys)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nedge_neighbourhood = [\n    [33, 130, 90, 110, 71],\n    [19, 64, 121, 150, 128],\n    [45, 52, 65, 97, 89],\n    [37, 69, 30, 40, 115],\n    [38, 37, 53, 52, 26]\n];\nimshow(edge_neighbourhood, 40, d3.interpolateGreys)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntuitively we can sort of see that the righthand group looks like it could contain an edge, but how do we objectively measure that? Looking at the statistics of each neighbourhood,\n\n\n\n\n\n\n\n\n\n\n\n(a) Homogenous neighbourhood\n\n\n\n\n\n\n\n\n\n\n\n(b) Edge neighbourhood\n\n\n\n\n\n\n\nFigure 1: Corresponding brightness histograms (blue) and associated Gaussian curves (orange)\n\n\n\nwe see that the homogenous one is monomodal – a single ‘hump’, whereas the edge neighbourhood appears more bimodal – two humps. This makes sense, since in the edge neighbourhood there are two types of objects whose values are randomly deviated from via speckle.\nIf we wanted some individual number that reflected this, we could just grab the variance. The homogenous neighbourhood has a variance of 948, compared to the edge neighbourhood’s 1428. This makes sense since the edge neighbourhood has two different ‘types’ of pixels doing two different, unrelated things and are thus spread over a larger range of brightnesses. The edge neighbourhood is more varied.\nSo we can argue that if a neighbourhood has high variance, it’s more likely to be an edge neighbourhood. If it’s not an edge neighbourhood, there’s no reason not to use the blur filter to reduce speckle. And if it is, then we might want to weaken the blur to minimize edge bleeding. We could construct a new, adaptive filter:\n\\[\nf =\n\\alpha\n\\begin{bmatrix}\n    0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 0 \\\\\n\\end{bmatrix}\n+\n(1-\\alpha)\n\\begin{bmatrix}\n    .35 & 45 & .5 & .45 & .35 \\\\\n    .45 & 0.7 & 1 & 0.7 & .45 \\\\\n    .5 & 1 & 5 & 1 & .5 \\\\\n    .45 & 0.7 & 1 & 0.7 & .45 \\\\\n    .35 & .45 & .5 & .45 & .35 \\\\\n\\end{bmatrix}\n\\]\nHere the smaller \\(\\alpha\\) is, the stronger the blur. Since we identified variance as our measure for whether or not the neighbourhood may contain an edge (and thus whether to blur), we can just let \\(\\alpha = \\frac{var}{mean^2}\\). Here we’ve divided by the (squared) mean so that we can work in terms of a unitless fraction.\nOne last step we might take is to scale the whole thing exponentially. This essentially just shifts voting power even more strongly towards ‘trustworthy’ pixels:\n\n\n\n\n\n\n\n\nFigure 2: Effect of switching to exponential relationship between weights and pixel scores\n\n\n\n\n\nFinally then, in other words the weight or ‘voting power’ assigned to a pixel is:\n\\[\nw = e^{-D \\alpha \\kappa}\n\\]\nwhere \\(D\\) is the distance from the centre to that pixel, \\(\\alpha\\) is the (fractional) neighbourhood variance and \\(\\kappa\\) is just a number we can mess with to change how gnarly the exponential curve is.\nBasically pixels are less ‘trustworthy’ if they are further away, and all pixels except the centre are less ‘trustworthy’ if the neighbourhood has a lot of variation. Then actual voting power is assigned exponentially to really penalize ‘untrustworthy’ pixels. The result is that in a seemingly homogenous neighbourhood, we blur per usual. In a neighbourhood that contains an edge, we blur just a little bit. And in a neighbourhood where it’s kind of hard to tell if it’s homogenous or an edge, we hedge our bets and blur moderately. This is an adaptive filter. In fact, we just built the well-known Frost Filter!\n\n\nCode\nimport {imshow} from \"@sw1227/reusable-2d-array-image-function\"",
    "crumbs": [
      "Teaching",
      "SAR Speckle and Filtering",
      "Speckle filtering (adaptive)"
    ]
  },
  {
    "objectID": "teaching/SAR_speckle_and_filtering/speckle_solar_radiation.html",
    "href": "teaching/SAR_speckle_and_filtering/speckle_solar_radiation.html",
    "title": "Natural light and the absence of speckle",
    "section": "",
    "text": "Armed with an understanding of this new light phenomenon, we might ask the obvious question: Why doesn’t normal light behave this way? Certainly when we look at an object using an optical satellite, or even just our own eyes, it doesn’t appear speckley. What gives? Let’s simply resimulate the prior situation using light from the sun; note that unlike our “pure” 50cm wave before, solar radiation is the confluence of many different frequencies in different proportion:\n\n\nCode\nviewof form_nl1 = Inputs.form(\n    [\n        Inputs.range([0, 1000], {label: html`&lt;font size=\"3.5\"&gt;Offset&lt;/font&gt;`, step: 1, value: 500}),\n        Inputs.range([0, 20], {label: html`&lt;font size=\"3.5\"&gt;Speed&lt;/font&gt;`, step: 1, value: 10})\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}&lt;/div&gt;`\n    }\n)\n\nphase_diff_nl  = form_nl1[0];\nspeed_nl = form_nl1[1];\n\n\ndistance_nl = 400;\nNumPoints_nl = 1000;\nNumWaves_nl = 20\nwavelengths_nl = [1,2,3,5,8,10,11,14,15,17,19,20,23,25,26,28,29,32,33,35]\nphases_nl = [0,0.4,1,0.5,2,3.1,4,4.9,1.3,.8,6,2.2,2.8,1.7,.85,.9,3,2.4,1.8,1.3];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwave_nl1 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints_nl; i++) {\n        var y = 0\n        for (var k = 1; k &lt; NumWaves_nl; k++) {\n            var j = i * distance_nl / NumPoints_nl;\n            y += 7 * Math.sin(j * 2*Math.PI / wavelengths_nl[k] + time + phases_nl[k])\n        }\n        data.push([j,y]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwave_nl2 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints_nl; i++) {\n        var y = 0\n        for (var k = 1; k &lt; NumWaves_nl; k++) {\n            var j = i * distance_nl / NumPoints_nl;\n            y += 7 * Math.sin(j * 2*Math.PI / wavelengths_nl[k] + time + phases_nl[k] + phase_diff_nl/wavelengths_nl[k])\n        }\n        data.push([j,y]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwavesum_nl = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints_nl; i++) {\n        var y = 0\n        for (var k = 1; k &lt; NumWaves_nl; k++) {\n            var j = i * distance_nl / NumPoints_nl;\n            y += 7 * Math.sin(j * 2*Math.PI / wavelengths_nl[k] + time + phases_nl[k]) + 7 * Math.sin(j * 2*Math.PI / wavelengths_nl[k] + time + phases_nl[k] + phase_diff_nl/wavelengths_nl[k])\n        }\n        data.push([j,y]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nrnl = d3.line()(wave_nl1);\nbnl = d3.line()(wave_nl2);\nsvg`&lt;svg viewBox=\"0 -64 400 128\"&gt;\n  &lt;path d=\"${rnl}\" stroke=\"red\" fill=\"none\" /&gt;\n  &lt;path d=\"${bnl}\" stroke=\"blue\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npnl = d3.line()(wavesum_nl);\nsvg`&lt;svg viewBox=\"0 -128 400 256\"&gt;\n  &lt;path d=\"${pnl}\" stroke=\"black\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntime = {\n  let i = 0;\n  while (true) {\n    i += speed_nl * 0.01;\n    yield i\n  }\n}\n\n\n\n\n\n\n\nHere we’ve made the blue/red waves the sum of about 20 different wavelengths roughly proportionate to the visual spectrum range to represent natural light. Chaotic! Try slowing down the speed to zero and manipulating the offset value. Notice that if the offset is zero the sum is quite large, which makes sense, since it then represents essentially a doubly-bright individual target. But if we give it any appreciable offset, representing two separate targets, we quickly decay down to a sum which is itself chaotic but broadly about the same size regardless of the offset.\nEssentially, natural light is too “messy” to interfere with itself. Mathematically we might say that it isn’t periodic on any appreciable scale, so it never “syncs back up” if you offset it. Whereas two well-defined, periodic (RADAR) waves will cyclically constructively and deconstructively interfere, light composed of many sub-frequencies will not. While two periodic waves can sum to be twice as big or annihilate entirely, two piles of chaos kind of just always sum to a different pile of chaos.\nHence we don’t see speckle when considering natural light/solar radiation, and why speckle is such an alien phenomenon for us to consider.",
    "crumbs": [
      "Teaching",
      "SAR Speckle and Filtering",
      "Natural light and the absence of speckle"
    ]
  },
  {
    "objectID": "teaching/SAR_speckle_and_filtering/speckle_filters_static.html",
    "href": "teaching/SAR_speckle_and_filtering/speckle_filters_static.html",
    "title": "Speckle filtering (static)",
    "section": "",
    "text": "So how do we go about undoing this effect? Clearly multiplying the brightness of each pixel by a (normally-distributed) random number between 0 and 1 isn’t exactly a reversible function. But we can use some intuitive methods to clarify the images. Since we want to undo the variability it causes we can start by simply applying a ‘blur’ effect to the image to smooth it out; replacing every pixel with the average value of all nearby pixels.\nWe can represent that notationally using a matrix:\n\\[\n\\frac{1}{9}\n\\begin{bmatrix}\n    0 & 0 & 0 & 0 & 0 \\\\\n    0 & 1 & 1 & 1 & 0 \\\\\n    0 & 1 & 1 & 1 & 0 \\\\\n    0 & 1 & 1 & 1 & 0 \\\\\n    0 & 0 & 0 & 0 & 0 \\\\\n\\end{bmatrix}\n\\]\nindicating that the new value of the centre pixel is one times itself, plus one times each of the nearest eight pixels, all divided by 9 – a local average.\nWe can try implementing that (or any other simple filter) on a real SAR image below:\n\n\n\n\n\nCode\ndummy=5\n\n\n\n\n\n\n\n\n\n\nCode\ntex\n`\n\\:\\:\\:\\:\\:\\:\n\\begin{bmatrix}\n    ${fm[0][0]} & ${fm[0][1]} & ${fm[0][2]} & ${fm[0][3]} & ${fm[0][4]}\\\\ \n    ${fm[1][0]} & ${fm[1][1]} & ${fm[1][2]} & ${fm[1][3]} & ${fm[1][4]}\\\\ \n    ${fm[2][0]} & ${fm[2][1]} & ${fm[2][2]} & ${fm[2][3]} & ${fm[2][4]}\\\\ \n    ${fm[3][0]} & ${fm[3][1]} & ${fm[3][2]} & ${fm[3][3]} & ${fm[3][4]}\\\\ \n    ${fm[4][0]} & ${fm[4][1]} & ${fm[4][2]} & ${fm[4][3]} & ${fm[4][4]}\\\\ \n\\end{bmatrix}\n`\n\n\n\n\n\n\n\n\n\n\nCode\ndummy2=5\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof form_row1 = Inputs.form(\n    [\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\nviewof form_row2 = Inputs.form(\n    [\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\nviewof form_row3 = Inputs.form(\n    [\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 1}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\nviewof form_row4 = Inputs.form(\n    [\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\nviewof form_row5 = Inputs.form(\n    [\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n        Inputs.number([-50, 50], {step: 1, value: 0}),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\nfm = [\n    [form_row1[0], form_row1[1], form_row1[2], form_row1[3], form_row1[4]],\n    [form_row2[0], form_row2[1], form_row2[2], form_row2[3], form_row2[4]],\n    [form_row3[0], form_row3[1], form_row3[2], form_row3[3], form_row3[4]],\n    [form_row4[0], form_row4[1], form_row4[2], form_row4[3], form_row4[4]],\n    [form_row5[0], form_row5[1], form_row5[2], form_row5[3], form_row5[4]],\n];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nopa = {\n    const imdata = await FileAttachment(\"//static/SAR_image.csv\").csv({ array: true, typed: true } );\n    return imdata.map(d =&gt; {\n        d.map(x =&gt; {\n            x = +x;\n            return x;\n        })\n        return d; \n    });\n}\n\n\n\n\n\n\n\n\n\nCode\nfmflat = fm.flat()\nfmsum  = fmflat.reduce((acc,value) =&gt; acc += Math.abs(value), 0);\nfpa = {\n    var fpa = [];\n    for (let i=0; i&lt;rowcount; i++){\n        fpa[i] = [];\n        for (let j=0;j&lt;columncount; j++){\n            var indices = [];\n            for (let x=-2; x&lt;3; x++){\n                for (let y=-2; y&lt;3; y++){\n                    if (i+x&gt;=0 && j+y&gt;=0 && i+x&lt;rowcount && j+y&lt;columncount){\n                        indices.push([i+x,j+y,fm[x+2][y+2]]);\n                    }}};\n            var pix=0;\n            var scale=0;\n            indices.forEach(function(item,index){\n                pix += opa[item[0]][item[1]] * item[2];\n                scale += Math.abs(item[2])\n            });\n            scale = fmsum/scale\n\n            fpa[i][j] = pix*scale;\n\n        }\n    }\n    return fpa;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimshow(fpa, 2, d3.interpolateGreys)\n\n\n\n\n\n\n\n\n\n\nCode\nimshow(opa, 2, d3.interpolateGreys)\n\n\n\n\n\n\n\n\n\nCode\nrowcount = 250;\ncolumncount = 370;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport {imshow} from \"@sw1227/reusable-2d-array-image-function\"\n\n\n\n\n\n\n\n\n\nCode\nmath = require(\"mathjs@7\")\n\n\n\n\n\n\n\n\nTry to construct filters which do the following:\n\n\n\nInverts the image brightness\nShifts the entire image two pixels to the right\nBlurs the image\nBlurs the image but gives more power to near pixels then far pixels\nHighlights vertical edges\nHighlights horizontal edges\nHighlights both vertical and horizontal edges\nI don’t know does something funky then explain why it does that\n\n\n\n\nHint\n\nWe just want every pixel to be itself but negative\n\n\n\nHint\n\nWe just want every pixel to be the one over on the right and not itself\n\n\n\nHint\n\nWe want every nearby pixel to have an equal contribution\n\n\n\nHint\n\nWe want every nearby pixel to have an unequal contribution\n\n\n\nHint\n\nWe want to know when the pixel above is very different from the pixel below\n\n\n\nHint\n\nWe want to know when the pixel to the left is very different from the pixel to the right\n\n\n\nHint\n\nWe want to know when the centre pixel is very different from the pixels above, below, left, and right\n\n\n\nHint\n\nWhat do you expect me to type here this is on you",
    "crumbs": [
      "Teaching",
      "SAR Speckle and Filtering",
      "Speckle filtering (static)"
    ]
  },
  {
    "objectID": "teaching/SAR_speckle_and_filtering/speckle.html",
    "href": "teaching/SAR_speckle_and_filtering/speckle.html",
    "title": "Speckle as an interference phenomenon",
    "section": "",
    "text": "Let’s look an illustrative real-world manifestation of this conceptual framework. SAR images are subject to speckle, a type of image distortion or noise which affects pixels in a stochastic, multiplicative way. Why does this occur?\nConsider that the returned wave associated with a given pixel likely isn’t the result of a single interation with a single pointwise object. If multiple reflectors (or similarly, a continuous reflector) lie within the pixel, then the returned wave is the sum of multiple individual waves.\nLet’s imagine we have a pixel with two identical point reflectors lying within it. How does the returned wave change as a function of where those reflectors are located? Move the blue and red targets in the pixel below:\n\nCode\nchart = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    // define a bounding rectangle\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", height - 2*stroke_width)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 0.087124976) //This is a hard-coded value based on the prescribed physical parameters. It's hardcoded because it's easier than dealing with the resulting reactive dependencies since this cell should never be run again\n\n    // define data used for circles\n    const circles = d3.range(2).map(i =&gt; ({\n        x: (i+2) * width / 5,\n        y: (i+1) * height / 3,\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", d =&gt; d.x)\n            .attr(\"cy\", d =&gt; d.y)\n            .attr(\"r\", radius)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[d.index * 3])\n            .attr(\"id\", function(d,i) {return i})\n            .call(drag)\n\n    return svg.node();\n}\nchart2 = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    //define a function to take the canvas position of the leftside chart to the\n    //  corresponding region in the second chart\n    //  it's messy because I solved the system by hand and didn't simplify, RIP\n    //  to future Jake if I ever have to un-hardcode the object position values\n    function lineartransform(xposition){\n        return (2*height/5 - radius)/(5/7*width -2*radius-2)*xposition + width/7 + 2/5*height + radius/2 - (2*height/5 - radius)*(width/7+radius+1)/(5/7*width-2*radius-2)\n    }\n\n    // define a earth curvature line\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", height - 2*stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", stroke_width/2)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 0)\n\n    // define lines going from the target to the satellites (first, so they appear under them)\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 3*height/20)\n        .attr(\"x2\", lineartransform(x1))\n        .attr(\"y1\", 3*height/20)\n        .attr(\"y2\", height - 2*stroke_width)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"blue\")\n\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 3*height/20)\n        .attr(\"x2\", lineartransform(x2))\n        .attr(\"y1\", 3*height/20)\n        .attr(\"y2\", height - 2*stroke_width)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"red\")\n\n\n    // define a rectangle representing the satellite\n    svg.append(\"rect\")\n        .attr(\"x\", width/7 + height/10)\n        .attr(\"y\", height/10)\n        .attr(\"width\", height/10)\n        .attr(\"height\", height/10)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", .50)\n    \n    // define notches indicating the bounds of the pixel\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 2*height/5)\n        .attr(\"x2\", width/7 + 2*height/5)\n        .attr(\"y1\", height - 2*stroke_width)\n        .attr(\"y2\", height - 2*stroke_width - height/20)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"black\")\n\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 4*height/5)\n        .attr(\"x2\", width/7 + 4*height/5)\n        .attr(\"y1\", height - 2*stroke_width)\n        .attr(\"y2\", height - 2*stroke_width - height/20)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"black\")\n\n    // define data used for circles\n    const circles = d3.range(2).map(i =&gt; ({\n        x: (i+2) * width / 5,\n        y: (i+1) * height / 3,\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", function(d,i) {\n                if (i == 0) {return lineartransform(x1)}\n                else {return lineartransform(x2)}\n            })\n            .attr(\"cy\", height - 2*stroke_width)\n            .attr(\"r\", radius/2)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[d.index * 3])\n            .attr(\"id\", function(d,i) {return i})\n\n    // add text\n    svg.append(\"text\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", .94*height)\n        .style(\"font-size\", \"28px\")\n        .text(\"side view\")\n\n    svg.append(\"text\")\n        .attr(\"x\", width/2)\n        .attr(\"y\", .15*height)\n        .style(\"font-size\", \"24px\")\n        .style(\"font-style\", \"italic\")\n        .text(\"*wildly not to scale\")\n\n    return svg.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nformatted_d1 = (0.5*distance_travelled_w1).toFixed(2).replace(/\\B(?&lt;!\\.\\d*)(?=(\\d{3})+(?!\\d))/g, \",\");\nformatted_d2 = (0.5*distance_travelled_w2).toFixed(2).replace(/\\B(?&lt;!\\.\\d*)(?=(\\d{3})+(?!\\d))/g, \",\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistance from target one to the satellite: m\nDistance from target two to the satellite: m\n\n\n\nCode\n// defines how circles change appearance and position in response to cursor drag\ndrag = {\n\n    // move the circles to cursor position when dragging is active\n    function dragged(event, d){\n        var newx = event.x;\n        if (newx &lt; xbounds[0]) newx = xbounds[0];\n        if (newx &gt; xbounds[1]) newx = xbounds[1];\n        var newy = event.y;\n        if (newy &lt; ybounds[0]) newy = ybounds[0];\n        if (newy &gt; ybounds[1]) newy = ybounds[1];\n        \n        if (d3.select(this).attr('id') == \"0\") {\n            mutable x1 = newx;\n            mutable y1 = newy;\n        }\n        if (d3.select(this).attr('id') == \"1\") {\n            mutable x2 = newx;\n            mutable y2 = newy;\n        }\n        \n        d3.select(this).raise().attr(\"cx\", d.x = newx).attr(\"cy\", d.y = newy);\n\n        var dt1 = 2*Math.sqrt(sat_z**2 + (mutable x1/width*pixel_width - sat_x)**2 + (mutable y1/width*pixel_width - sat_y)**2);\n        var dt2 = 2*Math.sqrt(sat_z**2 + (mutable x2/width*pixel_width - sat_x)**2 + (mutable y2/width*pixel_width - sat_y)**2);\n        var p1  =  dt1 / wavelength *2 *Math.PI;\n        var p2  =  dt2 / wavelength *2 *Math.PI;\n\n        d3.select(\"rect\").attr(\"fill-opacity\", 1-Math.abs(Math.cos((p1-p2)/2)));\n        //d3.select(\"text\").text(1-Math.abs(Math.cos((p1-p2)/2))).style(\"fill\",\"darkOrange\");\n    }\n\n    // map the d3 drag event functionality to these custom functions\n    return d3.drag()\n        .on(\"drag\", dragged)\n}\n\n\n\n\n\n\n\n\n\nCode\nmutable x1= 2*width/5;\nmutable y1= height/3;\nmutable x2= 3*width/5;\nmutable y2= 2*height/3;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nstroke_width = 7;\nwidth = 700;\nheight = 500 + 2*stroke_width;\nradius = 25;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nxbounds = [width/7 + radius + 1, 6*width/7 - radius - 1]\nybounds = [ radius + 1  + stroke_width, height - radius - 1 - stroke_width]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndistance = 4;\nNumPoints = 1000;\nwavelength = .5;\namplitude = 15;\nspeed = 10;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n// display variables\nxscale_factor = 100;\n\n\n\n\n\n\n\n\n\nCode\nsat_x = -100000;\nsat_y = 100000;\nsat_z = 600000;\npixel_width = 3;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndistance_travelled_w1 = 2*Math.sqrt(sat_z**2 + (x1/width*pixel_width - sat_x)**2 + (y1/width*pixel_width - sat_y)**2);\ndistance_travelled_w2 = 2*Math.sqrt(sat_z**2 + (x2/width*pixel_width - sat_x)**2 + (y2/width*pixel_width - sat_y)**2);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nphase_w1 = distance_travelled_w1 / wavelength *2 *Math.PI;\nphase_w2 = distance_travelled_w2 / wavelength *2 *Math.PI;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwave1 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j*xscale_factor, amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w2)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwave2 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j*xscale_factor , amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w1)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwaveSum = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j*xscale_factor , amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w1) + amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w2)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\ntime = {\n  let i = 0;\n  while (true) {\n    i += speed * 0.01;\n    yield i\n  }\n}\n\n\n\n\n\n\n\n\n\nCode\nr = d3.line()(wave1);\nb = d3.line()(wave2);\nsvg`&lt;svg viewBox=\"0 -32 400 64\"&gt;\n  &lt;path d=\"${r}\" stroke=\"red\" fill=\"none\" /&gt;\n  &lt;path d=\"${b}\" stroke=\"blue\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np = d3.line()(waveSum);\nsvg`&lt;svg viewBox=\"0 -64 400 130\"&gt;\n  &lt;path d=\"${p}\" stroke=\"black\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nd3 = require(\"d3@7\")\n\n\n\n\n\n\n\nHere we’ve considered a SAR satellite 600km above Earth, emitting 50cm wavelength radiation with a pixel resolution of 3m.\nThe distance from each target to the satellite affects where in their cycle each wave is re-intercepted, and thus the difference determines whether those returned waves interfere constructively or deconstructively. Thus a random distribution of targets creates a random difference in distance to the satellite, creating a random level of interference in each pixel. This means the intensity of each pixel is randomly (though not necessarily uniformly) multiplied by a value from 0 (perfect deconstructive interference) to 1 (perfect constructive interference). This is the origin of speckle, and reason why it manifests as multiplicative noise (as opposed to additive).\nLet’s now consider two pixels: one with more, stronger scatterers and one with fewer, weaker scatterers – perhaps pixel one belongs to some dense shrubland, while the other is a freshly plowed field. The distribution of scatterers is likely quite random – what happens to the brightness of these pixels under different configurations?\n\n\nCode\ntargetnum_1 = 10;\ntargetnum_2 = 10;\nmax_radius_p1 = 35;\nmin_radius_p1 = 25;\nmax_radius_p2 = 20;\nmin_radius_p2 = 15;\n\nradii_p1 = {\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_1; i++) {\n            data.push(Math.random()*(max_radius_p1-min_radius_p1) + min_radius_p1);\n        }\n    return data;\n}\n\nradii_p2 = {\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_2; i++) {\n            data.push(Math.random()*(max_radius_p2-min_radius_p2) + min_radius_p2);\n        }\n    return data;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof reroll_toggle = Inputs.form(\n    [\n        Inputs.button(\"Redistribute Targets\"),\n        Inputs.button(\"Auto Redistribute Targets\"),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    })\n\nvtoggle1    = reroll_toggle[0];\nauto_toggle = reroll_toggle[1];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntime_auto = {\n  let i = 0;\n  while (auto_toggle%2==1) {\n    i += 1;\n    yield i\n  }\n}\n\n\n\n\n\n\n\n\n\nCode\npixel1_positions = {\n    var dummy  = vtoggle1;\n    var dummy2 = time_auto;\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_1; i++) {\n            var x = Math.random()*(5*width/7 - 2*max_radius_p1) + max_radius_p1 + width/7;\n            var y = Math.random()*(height - 2*max_radius_p1) + max_radius_p1;\n            data.push([x,y]);\n        }\n    return data\n}\n\npixel2_positions = {\n    var dummy  = vtoggle1;\n    var dummy2 = time_auto;\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_2; i++) {\n            var x = Math.random()*(5*width/7 - 2*max_radius_p1) + max_radius_p1 + width/7;\n            var y = Math.random()*(height - 2*max_radius_p1) + max_radius_p1;\n            data.push([x,y]);\n        }\n    return data\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n//two pixels with targets in them\n\nchart3 = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    // define a bounding rectangle\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", height - 2*stroke_width)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 1-amplitude_p1/200)\n\n    // define data used for circles\n    const circles = d3.range(targetnum_1).map(i =&gt; ({\n        x: pixel1_positions[i][0],\n        y: pixel1_positions[i][1],\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", d =&gt; d.x)\n            .attr(\"cy\", d =&gt; d.y)\n            .attr(\"r\", function(d,i) {return radii_p1[i]})\n            .attr(\"stroke\", \"black\")\n            .attr(\"stroke-width\", 4)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[0])\n            .attr(\"id\", function(d,i) {return i})\n\n    return svg.node();\n}\nchart4 = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    // define a bounding rectangle\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", height - 2*stroke_width)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 1-amplitude_p2/200)\n\n    // define data used for circles\n    const circles = d3.range(targetnum_2).map(i =&gt; ({\n        x: pixel2_positions[i][0],\n        y: pixel2_positions[i][1],\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", d =&gt; d.x)\n            .attr(\"cy\", d =&gt; d.y)\n            .attr(\"r\", function(d,i) {return radii_p2[i]})\n            .attr(\"stroke\", \"black\")\n            .attr(\"stroke-width\", 4)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[0])\n            .attr(\"id\", function(d,i) {return i})\n\n    return svg.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n    round: true,\n    color: {legend: true},\n    x: {label: \"Brightness\"},\n    y: {label: \"Frequency\"},\n    marks: [\n        Plot.rectY(brightnesses, Plot.binX({y2: \"count\"}, {x: \"x\", fill: \"p\", mixBlendMode: \"multiply\"})),\n        Plot.ruleY([0])\n        ]\n})\n\n\n\n\n\n\n\n\n\nCode\namplitude_p1 = {\n\n    var dummy = vtoggle1;\n    \n    var amplitude_naught = radii_p1[0];\n\n    var dt_naught =\n        2*Math.sqrt(\n            sat_z**2\n            + (pixel1_positions[0][0]/width*pixel_width - sat_x)**2\n            + (pixel1_positions[0][1]/width*pixel_width - sat_y)**2\n        );\n    \n    var phase_naught =\n        dt_naught / wavelength *2 *Math.PI;\n    \n    //successively add the waves, determining the new phases and amplitudes\n    for (var i = 1; i &lt;= targetnum_1-1; i++) {\n        //compute the phase of the next subwave\n        var dt_next =\n            2*Math.sqrt(\n                sat_z**2\n                + (pixel1_positions[i][0]/width*pixel_width - sat_x)**2\n                + (pixel1_positions[i][1]/width*pixel_width - sat_y)**2\n        );\n\n        var phase_next = \n            dt_next / wavelength *2 *Math.PI;\n        \n        //compute the amplitude of the new sum\n        var new_amplitude =\n            Math.sqrt(\n                amplitude_naught**2\n                + radii_p1[i]**2\n                + 2*amplitude_naught*radii_p1[i]*Math.cos(phase_next-phase_naught)\n            );\n\n        //compute the phase of the new sum\n        var new_phase =\n            Math.atan(\n                (amplitude_naught*Math.sin(phase_naught) + radii_p1[i]*Math.sin(phase_next))\n                /(amplitude_naught*Math.cos(phase_naught) + radii_p1[i]*Math.cos(phase_next))\n            )\n\n        amplitude_naught = new_amplitude;\n        phase_naught = new_phase;\n\n    }\n    return amplitude_naught\n}\n\namplitude_p2 = {\n\n    var dummy = vtoggle1;\n    \n    var amplitude_naught = radii_p2[0];\n\n    var dt_naught =\n        2*Math.sqrt(\n            sat_z**2\n            + (pixel2_positions[0][0]/width*pixel_width - sat_x)**2\n            + (pixel2_positions[0][1]/width*pixel_width - sat_y)**2\n        );\n    \n    var phase_naught =\n        dt_naught / wavelength *2 *Math.PI;\n    \n    //successively add the waves, determining the new phases and amplitudes\n    for (var i = 1; i &lt;= targetnum_1-1; i++) {\n        //compute the phase of the next subwave\n        var dt_next =\n            2*Math.sqrt(\n                sat_z**2\n                + (pixel2_positions[i][0]/width*pixel_width - sat_x)**2\n                + (pixel2_positions[i][1]/width*pixel_width - sat_y)**2\n        );\n\n        var phase_next = \n            dt_next / wavelength *2 *Math.PI;\n        \n        //compute the amplitude of the new sum\n        var new_amplitude =\n            Math.sqrt(\n                amplitude_naught**2\n                + radii_p2[i]**2\n                + 2*amplitude_naught*radii_p2[i]*Math.cos(phase_next-phase_naught)\n            );\n\n        //compute the phase of the new sum\n        var new_phase =\n            Math.atan(\n                (amplitude_naught*Math.sin(phase_naught) + radii_p2[i]*Math.sin(phase_next))\n                /(amplitude_naught*Math.cos(phase_naught) + radii_p2[i]*Math.cos(phase_next))\n            )\n\n        amplitude_naught = new_amplitude;\n        phase_naught = new_phase;\n\n    }\n    return amplitude_naught\n}\n\n{\nmutable brightnesses.push({x: amplitude_p1, p: \"Pixel 1\"});\nmutable brightnesses.push({x: amplitude_p2, p: \"Pixel 2\"});\nmutable brightnesses = mutable brightnesses;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n//histogram to be populated with the brightness values of the two pixels\nmutable brightnesses = [];\n\n\n\n\n\n\n\nSelecting the Auto Redistribute option to generate a few hundred random configurations of each pixel type, we can see in the developing histogram of their brightnesses that while the pixel with more strongly reflecting targets is on average brighter, there are many times when the pixel with weaker targets actually gives a higher return. This is due to the random level of interference we’ve called speckle. We can exploit the fact that the average value remains higher to identify likely high-return areas in speckle filtering. As an aside, notice that the distributions of brightness appear relatively Gaussian – this is a lovely invocation of the Central Limit Theorem.",
    "crumbs": [
      "Teaching",
      "SAR Speckle and Filtering",
      "Speckle as an interference phenomenon"
    ]
  },
  {
    "objectID": "teaching/coherence_and_polarization/sums_of_waves.html",
    "href": "teaching/coherence_and_polarization/sums_of_waves.html",
    "title": "Sums of Waves",
    "section": "",
    "text": "Remote sensing involves measuring light’s physical properties to determine what type of object it was emitted by or interacted with. Properties like energy and wavelength/frequency are straightforward enough to undertand and represent diagrammatically – however we often want to observe and explain more unintuitive properties like coherence or polarization state.\nThese properties are the basis of powerful techniques such as radar polarimetry, but they’re notoriously tricky to represent and absorb – it certainly doesn’t help that we need to visualize 4D objects, or that the properties are similar yet distinct, intimately related through statistics! Don’t worry though – here we will walk comfortably from first principles up to a working understanding of coherence and polarization state. And if you’re particularly brave continue on and we’ll tie them together under the umbrella of information theory by relating them to Shannon entropy.",
    "crumbs": [
      "Teaching",
      "Wave Coherence and Polarization State",
      "Sums of Waves"
    ]
  },
  {
    "objectID": "teaching/coherence_and_polarization/sums_of_waves.html#what-is-coherence-what-is-polarization-state",
    "href": "teaching/coherence_and_polarization/sums_of_waves.html#what-is-coherence-what-is-polarization-state",
    "title": "Sums of Waves",
    "section": "What is Coherence? What is Polarization State?",
    "text": "What is Coherence? What is Polarization State?\nIn reality, most EMR is not “perfectly polarized”. EMR can often be viewed as sums of waves with different frequencies. Try adding two different waves together to make strange new waveforms:\n\n\nCode\nviewof form_m1_1 = Inputs.form(\n    [\n        Inputs.range([1, 30], {label: html`&lt;font size=\"3.5\"&gt;Amplitude 1&lt;/font&gt;`, step: 1, value: 15}),\n        Inputs.range([1, 100], {label: html`&lt;font size=\"3.5\"&gt;Wavelength 1&lt;/font&gt;`, step: 1, value: 50})\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\namplitudeW1  = form_m1_1[0];\nwavelengthW1 = form_m1_1[1];\n\nviewof form_m1_2 = Inputs.form(\n    [\n        Inputs.range([1, 30], {label: html`&lt;font size=\"3.5\"&gt;Amplitude 2&lt;/font&gt;`, step: 1, value: 15}),\n        Inputs.range([1, 100], {label: html`&lt;font size=\"3.5\"&gt;Wavelength 2&lt;/font&gt;`, step: 1, value: 50})\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\namplitudeW2  = form_m1_2[0];\nwavelengthW2 = form_m1_2[1];\n\nviewof form_m1_3 = Inputs.form(\n    [\n        Inputs.range([0, 6.2], {label: html`&lt;font size=\"3.5\"&gt;Phase Diff&lt;/font&gt;`, step: 0.1, value: 0}),\n        Inputs.range([1, 20], {label: html`&lt;font size=\"3.5\"&gt;Speed&lt;/font&gt;`, step: 1, value: 10})\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\nphase_diff_m1  = form_m1_3[0];\nspeed_m1 = form_m1_3[1];\n\n\ndistance = 400;\nNumPoints = 1000;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwave1_m1 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j , amplitudeW1 * Math.sin(j * 2*Math.PI / wavelengthW1 + time)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwave2_m1 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j , amplitudeW2 * Math.sin(j * 2*Math.PI / wavelengthW2 + time + phase_diff_m1)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwaveSum_m1 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance / NumPoints;\n        data.push([j , amplitudeW1 * Math.sin(j * 2*Math.PI / wavelengthW1 + time) + amplitudeW2 * Math.sin(j * 2*Math.PI / wavelengthW2 + time + phase_diff_m1)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\ntime = {\n  let i = 0;\n  while (true) {\n    i += speed_m1 * 0.01;\n    yield i\n  }\n}\n\n\n\n\n\n\n\n\n\nCode\nr = d3.line()(wave1_m1);\nb = d3.line()(wave2_m1);\nsvg`&lt;svg viewBox=\"0 -32 400 64\"&gt;\n  &lt;path d=\"${r}\" stroke=\"red\" fill=\"none\" /&gt;\n  &lt;path d=\"${b}\" stroke=\"blue\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np = d3.line()(waveSum_m1);\nsvg`&lt;svg viewBox=\"0 -64 400 130\"&gt;\n  &lt;path d=\"${p}\" stroke=\"black\" fill=\"none\" /&gt;\n&lt;/svg&gt;`",
    "crumbs": [
      "Teaching",
      "Wave Coherence and Polarization State",
      "Sums of Waves"
    ]
  },
  {
    "objectID": "teaching/coherence_and_polarization/polarization_state_general.html",
    "href": "teaching/coherence_and_polarization/polarization_state_general.html",
    "title": "Polarization State (General)",
    "section": "",
    "text": "In reality however a wave is rarely ever perfectly of mono-frequency. Let’s see what happens when we substitute each of the original mono-frequency V and H waves with waves formed of multiple random nearby frequencies.\n\n\nCode\nviewof form1 = Inputs.form(\n    [\n        Inputs.range([1, 10], {label: \"# of Waves in V\",    step: 1, value: 1}),\n        Inputs.range([1, 10], {label: \"# of Waves in H\", step: 1, value: 1}),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\nnum_waves_V = form1[0];\nnum_waves_H = form1[1];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof form3 = Inputs.form(\n    [\n        Inputs.button(\"Toggle Sum\"),\n        Inputs.button(\"Toggle H and V\")\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    }\n)\n\nvtoggle1    = form3[0];\nvtoggle2    = form3[1];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nH_color = {return 0xff0000}\nV_color = {return 0x0000ff}\nS_color = {return 0x36454f}\n\nrender_HV = {\n    if(vtoggle2 % 2 == 0){return true}\n        else{return false}\n}\n\nrender_S = {\n    if(vtoggle1 % 2 == 0){return false}\n        else{return true}\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n{\n    const renderer = new THREE.WebGLRenderer({antialias: true, alpha: true});\n    invalidation.then(() =&gt; renderer.dispose());\n    renderer.setSize(width, height);\n    renderer.setPixelRatio(devicePixelRatio);\n    renderer.setClearColor( 0xffffff, 0 )\n    \n    const controls = new THREE.OrbitControls(camera, renderer.domElement);\n    controls.addEventListener(\"change\", () =&gt; renderer.render(scene, camera));\n    invalidation.then(() =&gt; (controls.dispose(), renderer.dispose()));\n    \n    while (true) {\n        renderer.render(scene, camera);\n        yield renderer.domElement;\n    }\n}\n\n\n\n\n\n\n\n\n\nCode\nscene = {\n  const scene = new THREE.Scene();\n  scene.background = null;\n  if (render_HV == true){\n    scene.add(line1);\n    scene.add(line2);\n  };\n  if (render_S == true){\n    scene.add(line3)\n  };\n  return scene;\n}\n\n\n\n\n\n\n\n\n\nCode\nline1 = {\n    const material = new THREE.LineMaterial({\n        color: V_color,\n        linewidth:3,\n    });\n\n    material.resolution.set(width, height);\n\n    const points = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var y= 0;\n        for (var j=0; j &lt; num_waves_V; j++){\n            y += (10 + 10/num_waves_V) * Math.sin(i/wavelengths_v[j] + phases[j])\n        }\n        points.push(i-NumPoints/2, y, 0);\n    }\n\n    const geometry = new THREE.LineGeometry().setPositions( points );\n    const line = new THREE.Line2( geometry, material );\n    return line;\n}\n\nline2 = {\n    const material = new THREE.LineMaterial({\n        color: H_color,\n        linewidth: 3,\n    });\n\n    material.resolution.set(width, height);\n\n    const points = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var x= 0;\n        for (var j=0; j &lt; num_waves_H; j++){\n            x += (10 + 10/num_waves_H) * Math.sin(i/wavelengths_h[j] + phases[j])\n        }\n        points.push(i-NumPoints/2, 0, x);\n    }\n\n    const geometry = new THREE.LineGeometry().setPositions( points );\n    const line = new THREE.Line2( geometry, material );\n    return line;\n}\n\n\nline3 = {\n    const material = new THREE.LineMaterial({\n        color: S_color,\n        linewidth:3,\n    });\n\n    material.resolution.set(width, height);\n\n    const points = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var x = 0;\n        for (var j=0; j &lt; num_waves_H; j++){\n            x += (10 + 10/num_waves_H) * Math.sin(i/wavelengths_h[j] + phases[j])\n        }\n        var y = 0;\n        for (var k=0; k &lt; num_waves_V; k++){\n            y += (10 + 10/num_waves_V) * Math.sin(i/wavelengths_v[k] + phases[k])\n        }\n        points.push(i-NumPoints/2, y, x);\n    }\n\n    const geometry = new THREE.LineGeometry().setPositions( points );\n    const line = new THREE.Line2( geometry, material );\n    return line;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncamera = {\n    const camera = new THREE.PerspectiveCamera( 45, window.innerWidth / window.innerHeight, 1, 500 );\n    camera.position.set( 100, 100, 100 );\n    camera.lookAt( 0, 0, 0 );\n    return camera;\n}\n\n\n\n\n\n\n\n\n\nCode\nheight = 600;\nNumPoints = 200;\nNumPoints_ellipse = 200;\n\npeturbv = [0,-1,5,-2,-3,2,3,-5,-6,4]\nwavelengths_v = {\n    var data = [];\n    for (var i=0; i&lt;10; i++){\n        data.push(10+peturbv[i]*.2)\n    }\n    return data;\n}\n\npeturbh = [0,-3,1,-4,-1,6,5,-5,-2,3]\nwavelengths_h = {\n    var data = [];\n    for (var i=0; i&lt;10; i++){\n        data.push(10+peturbh[i]*.2)\n    }\n    return data;\n}\n\nphases = [0,0,1,0.5,2,3.1,4,4.9,1.3,.8,6];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nversion=`0.130.0`;\nTHREE = {\n    const THREE = window.THREE = await require(`three@${version}/build/three.min.js`);\n    await require(`three@${version}/examples/js/controls/OrbitControls.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/LineSegments2.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/LineSegmentsGeometry.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/Line2.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/LineGeometry.js`).catch(() =&gt; {});\n    await require(`three@${version}/examples/js/lines/LineMaterial.js`).catch(() =&gt; {});\n\n    return THREE;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nellipse_points = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var x = 0;\n        for (var j=0; j &lt; num_waves_H; j++){\n            x += (5 + 10/num_waves_H) * Math.sin(i/wavelengths_h[j] + phases[j])\n        }\n        var y = 0;\n        for (var k=0; k &lt; num_waves_V; k++){\n            y += (5 + 10/num_waves_V)  * Math.sin(i/wavelengths_v[k] + phases[k])\n        }\n        data.push([-x,-y]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nellipse = d3.line()(ellipse_points);\nsvg`&lt;svg viewBox=\"-50 -50 100 100\"&gt;\n  &lt;path d=\"${ellipse}\" stroke=\"gray\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur earlier notion of wave coherence in 2D has moved into 3D adding a fourth polarization parameter: the degree of polarization. DOP is a measure of the degree of correlation between the wave’s geometric oscillations in time. We can then describe a polarization state in terms of some “average” pure state (3 parameters) which is deviated from by an amount commensurate to the degree of polarization (1 parameter). Although we might expect there to be infinitely many distinct curves with the same corresponding pure state and degree of polarization, in practice the distinction is unimportant as those states share the same physical properties in the aggregate. This gives fits nicely with experimentally-obtained descriptions of polarization such as the Stokes parameters.",
    "crumbs": [
      "Teaching",
      "Wave Coherence and Polarization State",
      "Polarization State (General)"
    ]
  },
  {
    "objectID": "teaching/teaching_landingpage.html",
    "href": "teaching/teaching_landingpage.html",
    "title": "Teaching",
    "section": "",
    "text": "Are you a student in my class? A colleague? Graduate student desperately searching the web for an explanation of an obscure concept? Here you’ll find a selection of teaching resources associated with my classes and workshops.\n\n “Teaching cannot remain the top-down pouring of knowledge into otherwise passive students’ minds. If we are to seriously consider constructivism with its cognitive implications, and the interpersonal nature of learning with its social and organizational implications, and if we are to allow technology to be a lever for this kind of shift, then the prototypical kind of the learning environment described above is inevitable. Sure to follow are teamwork, the social appropriation of meaning rather than authority-sanctioned”true” knowledge, interdisciplinary materials, opening up of curricula, constant improvisation, and self-reliance of both teachers and students. But this vision implies a different kind of teacher. The new teachers are hardly ever going to have a detailed, well-worked-out curriculum to follow; they are not going to be the classroom authorities knowledgeable on everything; and they are not going to be the sole actors in the classroom. Instead, the teacher is going to be an autonomous, confident, widely knowledgeable professional, a team player, and a flexible improviser.” -Gavriel Salomon (1)\n\n\n\n\nReferences\n\n1. Salomon G. Technology’s promises and dangers in a psychological and educational context. Theory into practice. 1998;37(1):4–10.",
    "crumbs": [
      "Teaching"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "contact",
    "section": "",
    "text": "text text text"
  },
  {
    "objectID": "misc/funandgames/birble.html",
    "href": "misc/funandgames/birble.html",
    "title": "Birble",
    "section": "",
    "text": "I am currently incomplete! Come back… later!\nIdentify the bird in question by spending points to uncover information about its appearance, behaviour, and more!\n\n\nCode\nviewof score = Inputs.number([0, 100], {step: 1, label: \"Score\", value:20, disabled:true})\n\n\n\n\n\n\n\n\n\nCode\nbirbdata = [\n    [[\"Least Concern\"],[\"Nannopterum auritum\"]],\n    [[\"Least Concern\"],[\"Poecile atricapillus\"]],\n    [[\"Critical\"],[\"Gymnogyps californianus\"]],\n]\n\n\n\n\n\n\n\n\n\nCode\n// Helper function for synchronizing variables across cells, see https://observablehq.com/@observablehq/synchronized-inputs\nfunction adjust(input, value) {\n  // Set a new value to the input\n  input.value = input.value + value;\n  // Dispatch an update event to the input\n  input.dispatchEvent(new Event(\"input\", {bubbles: true}));\n}\n\n\n\n\n\n\n\n\n\nCode\nfunction set(input, value) {\n  input.value = value;\n  input.dispatchEvent(new Event(\"input\", {bubbles: true}));\n}\n\n\n\n\n\n\n\n\n\nCode\nviewof newbirb = html`&lt;button&gt;New Birb&lt;/button&gt;`;\n//html`&lt;p style=\"font-family:courier;\"&gt;This is a paragraph.&lt;/p&gt;`;\n// Select from array of birb data\ncurrent_birb = {\n  set(viewof score, 20);\n  const buttonClicked = await newbirb;\n  return birbdata[Math.floor(Math.random()*birbdata.length)];\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof CS = {\n  newbirb;\n  let value = 0;\n  const button = html`&lt;button&gt;[1] Conservation Status&lt;/button&gt;`;\n  Object.defineProperty(button, \"value\", {get() { return value; }});\n  button.onclick = () =&gt; ++value;\n  return button;\n}\n\nCStext = {\n    if (CS &gt; 0) {\n        //Adjust score at one button press asdas\n        if (CS == 1){adjust(viewof score,-1)};\n        //Change conservation status text\n        return (newbirb, current_birb[0][0])\n    } else {return \"\\n\"}\n}\n\n//Output conservation status text\nviewof CSA = Inputs.text({value:CStext, disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof BN = {\n  newbirb;\n  let value = 0;\n  const button = html`&lt;button&gt;[1] Binomial name&lt;/button&gt;`;\n  Object.defineProperty(button, \"value\", {get() { return value; }});\n  button.onclick = () =&gt; ++value;\n  return button;\n}\n\nBNtext = {\n    if (BN &gt; 0) {\n        //Adjust score at one button press asdas\n        if (BN == 1){adjust(viewof score,-1)};\n        //Change conservation status text\n        return (newbirb, current_birb[1][0])\n    } else {return \"\\n\"}\n}\n\n//Output conservation status text\nviewof BNA = Inputs.text({value:BNtext, disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompliance:\nThis material uses data from the eBird Status and Trends Project at the Cornell Lab of Ornithology, eBird.org. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Cornell Lab of Ornithology.\nRange data: Fink, D., T. Auer, A. Johnston, M. Strimas-Mackey, S. Ligocki, O. Robinson, W. Hochachka, L. Jaromczyk, C. Crowley, K. Dunham, A. Stillman, I. Davies, A. Rodewald, V. Ruiz-Gutierrez, C. Wood. 2023. eBird Status and Trends, Data Version: 2022; Released: 2023. Cornell Lab of Ornithology, Ithaca, New York. https://doi.org/10.2173/ebirdst.2022",
    "crumbs": [
      "-misc-",
      "Fun and Games",
      "Birble"
    ]
  },
  {
    "objectID": "misc/modding/moddingstardew.html",
    "href": "misc/modding/moddingstardew.html",
    "title": "Modding Stardew Valley for fun and (imaginary) profit",
    "section": "",
    "text": "Stardew Valley is an immensely popular slice-of-life game released in 2016 by ConcernedApe which teaches players the value of living in ecological balance with the environment, being connected to your local community, and digging through your neighbour’s trash bins. But what if we are unsatisfied with the default bevy of crops available to us? What if we want to farm species endemic to our region, or that are beneficial to local insects? What if your partner really likes tamarinds but you can’t find a mod pack with tamarind trees that doesn’t include like 50 other plants you don’t even want to deal with and the supplied image textures for breadfruit are awful like has this guy ever even seen breadfruit???1\nFortunately, you too can straightforwardly and safely modify your local game to warp reality to your capricious whims experiment with new ideas and get creative!\nThis quick guide will:\nThe main community resource for modding can be found here; this guide aims to streamline the process to a very specific and achievable goal in order to show anyone that they can try it too.",
    "crumbs": [
      "-misc-",
      "Modding",
      "Modding custom flora into Stardew Valley"
    ]
  },
  {
    "objectID": "misc/modding/moddingstardew.html#footnotes",
    "href": "misc/modding/moddingstardew.html#footnotes",
    "title": "Modding Stardew Valley for fun and (imaginary) profit",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAn all-too common occurence for many people, I’m sure↩︎\nMake sure you have also installed any mods that a given mod relies upon!↩︎",
    "crumbs": [
      "-misc-",
      "Modding",
      "Modding custom flora into Stardew Valley"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#earth-from-orbit-space-based-monitoring-of-a-planet-in-flux",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#earth-from-orbit-space-based-monitoring-of-a-planet-in-flux",
    "title": "jf_web",
    "section": "Earth From Orbit: Space Based Monitoring of a Planet in Flux",
    "text": "Earth From Orbit: Space Based Monitoring of a Planet in Flux\n\n\nJake E. Ferguson  UW Dept. Geography + Environmental Management  UW Water Institute  &lt;ja-fe.github.io&gt;",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#lhùààn-mân",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#lhùààn-mân",
    "title": "jf_web",
    "section": "Lhù’ààn Mân’",
    "text": "Lhù’ààn Mân’\n\n\nor: a somewhat distressing case study\n\n\n\nLargest lake in the Yukon: 400 km2\nHydrologically, ecologically, economically, and culturally vital\nIn 2016, water level dropped 2m",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#lhùààn-mân-1",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#lhùààn-mân-1",
    "title": "jf_web",
    "section": "Lhù’ààn Mân’",
    "text": "Lhù’ààn Mân’\n\n\nor: a somewhat distressing case study\n\n\nLargest lake in the Yukon: 400 km2\nHydrologically, ecologically, economically, and culturally vital\nIn 2016, water level dropped 2m",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#section-1",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#section-1",
    "title": "jf_web",
    "section": "",
    "text": "How many lakes are in Canada?",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#section-2",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#section-2",
    "title": "jf_web",
    "section": "",
    "text": "900,000\nHow many lakes are in Canada?",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#section-3",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#section-3",
    "title": "jf_web",
    "section": "",
    "text": "62% of world total count\n900,000\nHow many lakes are in Canada?",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#section-4",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#section-4",
    "title": "jf_web",
    "section": "",
    "text": "Most of ’em\n62% of world total count\n900,000\nHow many lakes are in Canada?",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#a-common-problem-on-planet-earth",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#a-common-problem-on-planet-earth",
    "title": "jf_web",
    "section": "A common problem on planet Earth",
    "text": "A common problem on planet Earth\n\n\n\nMillions of km2 to observe (Monthly! Weekly! Daily if you don’t mind!)\n\nVegetation [species, biomass, plant moisture levels]\nSoil [moisture]\nWater bodies [ice presense, ice type]\nAll current snow cover [density, water equivalent]\n\nHow do we monitor our planet?",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#a-common-problem-on-planet-earth-1",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#a-common-problem-on-planet-earth-1",
    "title": "jf_web",
    "section": "A common problem on planet Earth",
    "text": "A common problem on planet Earth\n\n\nMillions of km2 to observe (weekly! daily!)\n\nVegetation [species, biomass, plant moisture levels]\nSoil [moisture]\nWater bodies [ice presense, ice type]\nAll current snow cover [density, water equivalent]\n\nHow do we monitor our planet?\nSatellites",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#revisiting-kluane",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#revisiting-kluane",
    "title": "jf_web",
    "section": "Revisiting Kluane",
    "text": "Revisiting Kluane\n\n\n\n\n\nLet’s image the surface using a glorified camera advanced optical sensor!",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#revisiting-kluane-1",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#revisiting-kluane-1",
    "title": "jf_web",
    "section": "Revisiting Kluane",
    "text": "Revisiting Kluane\n\n\n\n\nLet’s image the surface using a glorified camera advanced optical sensor!\nPro: Works basically exactly how you think it does",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#revisiting-kluane-2",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#revisiting-kluane-2",
    "title": "jf_web",
    "section": "Revisiting Kluane",
    "text": "Revisiting Kluane\n\n\n\n\nLet’s image the surface using a glorified camera advanced optical sensor!\nPro: Works basically exactly how you think it does\nCon: So do clouds\nCon: Cameras are only skin deep",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#inspiration-from-venus",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#inspiration-from-venus",
    "title": "jf_web",
    "section": "Inspiration from Venus",
    "text": "Inspiration from Venus\n\n\n\n\n\n90s: Magellan probe is tasked with imaging Venus\nProblem: Venus is completely covered in sulfiric acid clouds\nSolution: Radio waves [RADAR]",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#irradiating-venus-just-a-little-as-a-treat",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#irradiating-venus-just-a-little-as-a-treat",
    "title": "jf_web",
    "section": "Irradiating Venus (just a little, as a treat)",
    "text": "Irradiating Venus (just a little, as a treat)",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#irradiating-venus-just-a-little-as-a-treat-1",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#irradiating-venus-just-a-little-as-a-treat-1",
    "title": "jf_web",
    "section": "Irradiating Venus (just a little, as a treat)",
    "text": "Irradiating Venus (just a little, as a treat)",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#tracking-the-original-amzn",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#tracking-the-original-amzn",
    "title": "jf_web",
    "section": "Tracking the original AMZN",
    "text": "Tracking the original AMZN",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#tracking-the-original-amzn-1",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#tracking-the-original-amzn-1",
    "title": "jf_web",
    "section": "Tracking the original AMZN",
    "text": "Tracking the original AMZN",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#tracking-the-original-amzn-2",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#tracking-the-original-amzn-2",
    "title": "jf_web",
    "section": "Tracking the original AMZN",
    "text": "Tracking the original AMZN",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#tracking-the-original-amzn-3",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#tracking-the-original-amzn-3",
    "title": "jf_web",
    "section": "Tracking the original AMZN",
    "text": "Tracking the original AMZN",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#po-river-2019",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#po-river-2019",
    "title": "jf_web",
    "section": "Po River, 2019",
    "text": "Po River, 2019",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#return-to-kluane",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#return-to-kluane",
    "title": "jf_web",
    "section": "Return to Kluane",
    "text": "Return to Kluane\n\n\n\n\nWe can cut right through the clouds using Canada’s own RADARSAT Constellation Mission!",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#where-does-that-leave-us",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#where-does-that-leave-us",
    "title": "jf_web",
    "section": "Where does that leave us?",
    "text": "Where does that leave us?",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#acknowledgement-and-final-note",
    "href": "outreach/talks/AstronomyOnTap2024/AstronomyOnTap2024.html#acknowledgement-and-final-note",
    "title": "jf_web",
    "section": "Acknowledgement and final note",
    "text": "Acknowledgement and final note\n\nThis work uses satellite imagery of land held and stewarded by the Kluane First Nation, and imagery of fieldwork conducted on Kluane lake which would simply not have been either safe or possible without the magnanimous help and consultation of the community there.\n\n&lt;ja-fe.github.io&gt;",
    "crumbs": [
      "Outreach",
      "Public Talks",
      "[Earth From Orbit:]{style=\"color:#5077c8\"} Space Based Monitoring of a Planet in Flux"
    ]
  },
  {
    "objectID": "about_jake.html",
    "href": "about_jake.html",
    "title": "Jake Ferguson",
    "section": "",
    "text": "Code\nmx = d3.max(gridData, d=&gt;d.x);\nmy = d3.max(gridData, d=&gt;d.y);\nheight = 460;\nwidth  = 300;\nnumCellsx = 21;\nnumCellsy = 32;\n\ngridData = {\n    var da = [];\n    var c = 0;\n    for (var j = 0; j &lt;= numCellsx; j++) {\n        for (var k = 0; k &lt;= numCellsy; k++) {\n        c+=1;\n        da.push({id:c,x:j,y:k,opa:1});\n    }}\n    return da;\n}\n\n{\n\n  var hover  = -10;\n  var ref_x  = 0;\n  var ref_y  = 0;\n  var dist   = 0;\n  var stophover = false\n  const svg = d3.select(DOM.svg(width, height));\n\n\n  svg.append(\"image\")\n    .attr(\"width\", \"100%\")\n    .attr(\"height\", \"100%\")\n    .attr(\"xlink:href\", \"static/logo_think.png\");\n\n  var node = svg.selectAll(\"g.node\")\n    .data(gridData, d =&gt; d.id)\n    \n  var nodeEnter = node.enter()\n    .append(\"svg:g\")\n    .attr(\"class\", \"node\")\n\n  nodeEnter.append(\"rect\")\n    .attr(\"id\", d =&gt; d.id)\n    .attr(\"x\", d =&gt; scale_x(d.x))\n    .attr(\"y\", d =&gt; scale_y(d.y))\n    .attr(\"width\", width/(mx+1))\n    .attr(\"height\", height/(my+1))\n    .attr(\"fill\", \"white\")\n    .attr(\"opacity\", function(d){\n      if (d.x &gt; numCellsx/3 && d.x &lt; numCellsx*.75 && d.y &gt; numCellsy/10 && d.y &lt; numCellsy/4.5) {\n        d.opa = 0\n        return 0}\n      else {return 1}\n    })\n    .on(\"mouseover\", function (event, d) {\n      if (!stophover){\n      hover = d.id\n      ref_x = d.x\n      ref_y = d.y\n      d3.selectAll(\"rect\")\n        //.transition()\n        //.delay(function(d,i){return Math.sqrt(Math.abs(d.x - ref_x)**2 + Math.abs(d.y - ref_y)**2);})\n        //.duration(1000)\n        //.attr(\"opacity\",0)\n        .attr(\"opacity\",function(d){\n          if (Math.sqrt(Math.abs(d.x - ref_x)**2 + Math.abs(d.y - ref_y)**2) &lt; 4.1) {\n            d.opa = d.opa*.93\n            return d.opa*.93}\n          else {return d3.select(this).attr(\"opacity\")}\n        })}\n    })\n    .on(\"click\", function (event, d) {\n      stophover = true\n      hover = d.id\n      ref_x = d.x\n      ref_y = d.y\n      d3.selectAll(\"rect\")\n        .transition()\n        .delay(function(d,i){return 100*Math.sqrt(Math.abs(d.x - ref_x)**2 + Math.abs(d.y - ref_y)**2)})\n        .duration(1000)\n        .attr(\"opacity\",function(d){\n          d.opa = 0\n          return 0\n        })\n    });\n\n  return svg.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nscale_x = d3.scaleLinear()\n  .domain([0, mx])\n  .range([0, width * (1-1/(mx+1))])\n\n\n\n\n\n\n\n\nCode\nscale_y = d3.scaleLinear()\n  .domain([0, my])\n  .range([0, height * (1-1/(my+1))])\n\n\n\n\n\n\n\nJake Ferguson\nJake (he/him) is a PhD Candidate in Geography and Environmental Management at the University of Waterloo. He’s interested in SAR Interferometry, SAR Polarimetry, producing open educational resources, and fussing over his website’s D3 renders.\nTo see an image of me, click here\n\n\n\nEducation\nUniversity of Waterloo | Waterloo, CA\nMSc. Physics, Computational Multiphysics Group | August 2019\nUniversity of Waterloo | Waterloo, CA\nBSc. Physics | April 2017\n\n\nSelect pubs\nPolarimetric decomposition of microwave-band freshwater ice SAR data: Review, analysis, and future directions"
  },
  {
    "objectID": "research/pedagogy/CUT_research_paper.html",
    "href": "research/pedagogy/CUT_research_paper.html",
    "title": "Interactive Simulations in Physics Education",
    "section": "",
    "text": "This document was written to fulfill the research paper component of the University of Waterloo’s Certificate in University Teaching program. It is not peer-reviewed or published in a formal journal.",
    "crumbs": [
      "Research",
      "Physics Pedagogy",
      "Interactive Simulations in Physics Education"
    ]
  },
  {
    "objectID": "research/pedagogy/CUT_research_paper.html#abstract",
    "href": "research/pedagogy/CUT_research_paper.html#abstract",
    "title": "Interactive Simulations in Physics Education",
    "section": "Abstract",
    "text": "Abstract\nThe use of interactive media including simulations, games, and responsive graphics in post-secondary education has increased commensurately with the proliferation of computing technology. Simulations can improve student engagement and facilitate discovery; interactive media can be especially useful in physics education, where concepts commonly have no obvious human-recognizable visual representation and often rely heavily on geometric analogy. Many authors in the last two decades have developed interactive simulations to teach concepts in fields such as electromagnetism and kinematics; large open educational resource (OER) collections of these media such as the University of Colorado’s Physics Education Technology (PhET) or the MyPhysicsLab project exist in an evolving educational ecosystem alongside commercial alternatives such as Pearson’s long-standing Mastering Physics courseware series and newer subscription-based libraries. While many authors have formally investigated the efficacy of these learning tools on student motivation and achievement, as well as developed data-based design principles, research investigating how best to incorporate these tools in course design is itself actively evolving. This paper reviews the former two items in the context of physics education, while casting a more critical eye to the latter and exploring the implementation of simulations in an undergraduate course.",
    "crumbs": [
      "Research",
      "Physics Pedagogy",
      "Interactive Simulations in Physics Education"
    ]
  },
  {
    "objectID": "research/pedagogy/CUT_research_paper.html#introduction-and-background",
    "href": "research/pedagogy/CUT_research_paper.html#introduction-and-background",
    "title": "Interactive Simulations in Physics Education",
    "section": "Introduction and Background",
    "text": "Introduction and Background\n\nInteractive Media in Education, Taxonomy\nInteractive media in education takes many forms, from simple navigable video clips and polling instruments to intricate webpages and simulations. All these tools seek to actively incorporate input from learners and react accordingly to demonstrate particular concepts or direct learning processes. This paper considers simulations or sims; sims are electronic representations of phenomena. Learners may alter key parameters of a sim, which then faithfully demonstrates the resulting dynamics or representation of the phenomenon. We may contrast a sim with an interactive webpage or application: whereas a webpage may display content or material based on learner input, even in a sophisticated manner such as through identifying a learner’s current interest or ability, a sim provides a responsive, representative environment in which exploration and experimentation can occur.\n\n\nInteractive Media in Education, Chronology\n\nor: For $4200 CAD, I can get you 512kb RAM and a simulated cannonball\nFormal academic interest in the efficacy and proper implementation of interactive media in higher education has existed as long as the technology itself: see e.g. reviews by Miller [1987] (1), De Jong and Van Joolingen [1998] (2), or Rutten et al. [2012] (3), which examine individual studies beginning in the early 1970s. Early authors were often attracted to computer simulations by the hope that they would better engender problem solving and inquiry skills (see e.g. (4,5)), as simulations offered students the ability to perform experiments both on phenomena which they normally couldn’t meaningfully control or perform experiments faster, cheaper, or more safely than in conventional laboratory settings.\nWhile individual early studies often showed ostensibly significant positive influences on student concept retention (6), hypothesis-forming (7), and attitude (8), meta analyses (attempting to synthesize these results into a cohesive pedagogical approach as computing technology became more widespread starting in the mid-1980s) found large variation in their efficacies. This was commonly attributed to the lack of consideration for how new technology was being incorporated into broader course design, with authors criticizing poor connection between simulations and lecture learning goals (1), simulations not being intentionally designed to facilitate hypothesis forming and data interpretation (2), and instructor passivity during simulation activities (3). We can ourselves readily find 20th century studies with no or negative results, e.g. (9).\nAn illustrative example can be found in a trio of early meta analyses published by Kulik, Kulik, and Bangert-Drowns examining the effectiveness of computer-based education in elementary (10), secondary (11), and post-secondary (12) settings. While the pre-university analyses found strong differences in efficacy based on the implementation of computer elements, these differences atrophied by the time learners entered university. The authors conjectured that this was due to the improved self-regulation capacity of older students, with the entertainment and structuring benefits of computer-assisted learning becoming less valuable. When we compare these initial results to more recent meta analyses which do show efficacy in post-secondary contexts (which are the beneficiaries of decades of research on integrating these tools into teaching theory), (e.g. (13)), we might argue that these tools do not intrinsically improve learning in higher education. While useful, these tools remain strongly reliant on their intentional integration into existing pedagogical strategies.\nIn the last twenty years research has studied the design and implementation of simulations for class contexts more thoroughly. As personal computing devices have become ubiquitous and capable, literature has explored connections with other developing pedagogical paradigms such as flipped-classroom learning (e.g. (14,15)) and game-based learning (e.g. (16–18)).\n\n\n\nA quick case for interactive media in physics\n\nor: The Board is Not Enough\nAlthough interactive media has been widely adopted by other fields including chemistry 1, biology2, and, appropriately enough, computer science3, we confine ourselves to considering its use in physics education. We can establish both the general merits of these tools in higher education, while noting the unique appeal it offers to physics educators. Many authors have critiqued or measured the ineffectiveness of conventional lectures for developing hypothesis-forming and intuition skills in physics undergraduates, see e.g. (22–24). Indeed in examining the literature, we might see the development of sims for physics education as a particular manifestation of broader trends towards inquiry- and active-learning based pedagogies.\nSims offer a representative environment which allows for learner-directed exploration of the phenomenon at hand; much contemporary literature examines sims through the lens of discovery/inquiry learning (26). Sims encourage students to form hypotheses and interrogate phenomena, instead of having an understanding recited to them. This flexibility allows students to form their own internal models for the concepts, and can have positive effects on engagement and interest (3).\n\nRepresentation\nMany physical disciplines are subject to issues of representation and the actual medium-based (as opposed to interactivity-, entertainment-, or inquiry-based) limitations of instructional elements. Student understanding of physical concepts is complicated by the fact that many relevant phenomena are largely if not entirely imperceptible to humans, or in the case of quantum phenomena, not directly observable at all. Several authors have tied this to the importance of model-building in physics education, arguing that being able to manipulate and switch between active representations improves learner’s ability to conceptualize difficult concepts e.g. (27)! Consider that if we subscribe to an analogy-centric view of explaining phenomena (a common enough perspective in contemporary physics literature, see e.g. reviews (28,29) and studies (30–32)), we find ourselves in the awkward position of having to create coherent references between an invisible process and some visible surrogate. Even having arrived at some representation which we find satisfying, we remain constrained by the medium used to actually… constitute it. By way of an example, consider we are tasked with introducing the polarization state of electromagnetic radiation to students using the representation of transverse waves. In a conventional classroom setting with access to chalk and board, we might invoke the following diagrams4:\n\nCode\nm1_wavelength = 50;\nm1_NumPoints  = 100;\nm1_distance   = 200; //Number of pixels width?\nm1_amplitude  = 15;\nm1_height     = 100;\n\n//Define the wave x,y values\nm1_wave = {\n    var data = [];\n    for (var i = 1; i &lt;= m1_NumPoints; i++) {\n        var j = i * m1_distance / m1_NumPoints;\n        data.push([j , m1_amplitude * Math.sin(j * 2*Math.PI / m1_wavelength)]);\n    }\n    return data;\n}\n\nm1_xaxis = {\n    var data = [];\n    for (var i = 0; i &lt;= 1; i++) {\n        var j = i * m1_distance;\n        data.push([j,0])\n    }\n    return data;\n}\n\nm1_yaxis = {\n    var data = [];\n    for (var i = 0; i &lt;= 1; i++) {\n        var j = i * m1_height - m1_height/2;\n        data.push([25,j])\n    }\n    return data;\n}\n\nm1_line  = d3.line()(m1_wave);\nm1_xaxis_line = d3.line()(m1_xaxis);\nm1_yaxis_line = d3.line()(m1_yaxis);\nsvg`&lt;svg viewBox=\"0 -32 200 64\"&gt;\n  &lt;path d=\"${m1_xaxis_line}\" stroke=\"black\" fill=\"none\" /&gt;\n  &lt;path d=\"${m1_yaxis_line}\" stroke=\"black\" fill=\"none\" /&gt;\n  &lt;path d=\"${m1_line}\" stroke=\"red\" fill=\"none\" /&gt;\n  &lt;text x=30 y=-20 font-size=\".4em\"&gt; t=0 &lt;/text&gt;\n  &lt;text x=19 y=-27 font-size=\".4em\"&gt; y &lt;/text&gt;\n  &lt;text x=2 y=-2  font-size=\".4em\"&gt; x &lt;/text&gt;\n&lt;/svg&gt;`\nm2_wave = {\n    var data = [];\n    for (var i = 1; i &lt;= m1_NumPoints; i++) {\n        var j = i * m1_distance / m1_NumPoints;\n        data.push([j , m1_amplitude * Math.sin(j * 2*Math.PI / m1_wavelength - Math.PI/3)]);\n    }\n    return data;\n}\n\nm2_line = d3.line()(m2_wave);\nsvg`&lt;svg viewBox=\"0 -32 200 64\"&gt;\n  &lt;path d=\"${m1_xaxis_line}\" stroke=\"black\" fill=\"none\" /&gt;\n  &lt;path d=\"${m1_yaxis_line}\" stroke=\"black\" fill=\"none\" /&gt;\n  &lt;path d=\"${m2_line}\" stroke=\"red\" fill=\"none\" /&gt;\n  &lt;text x=30 y=-20 font-size=\".4em\"&gt; t=10s &lt;/text&gt;\n  &lt;text x=19 y=-27 font-size=\".4em\"&gt; y &lt;/text&gt;\n  &lt;text x=2  y=6   font-size=\".4em\"&gt; x &lt;/text&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplaining that the magnetic component is pointing “into the board” and thus not visible. Stuck describing a 4D phenomenon (3 space + time) in a 2D medium (2 space and static), we rely on paired projections into the space to illustrate the dynamics. Even developing an enviable ability to draw in accurate 3D perspective, we would find ourselves a dimension short. Instead using a 4D medium (3 space and animated), we might invoke the following diagram (linked to decrease load on this page).\n\n\nInteractivity\nBut an ostensible improvement in representation still remains ‘flat’ until we put it into action: we need also consider the value of interactivity. In the prior diagram, we are given the freedom to drag and select a perspective of our choosing, to speed to the phenomenon up and down5. Critically however, we can alter the constituent red and blue base states to see the effect on the output grey state. This allows learners to construct their own nascent understanding of the geometry of polarization, beyond being simply told through 2D diagrams that these states exist under certain conditions. This is a basic instance of learning a complex topic through interrogation, investigation, inquiry, discovery, or whatever near-synonym suits you best – sims allow learners to observe and prod phenomena themselves.\n\n\nEfficiency and physics for the non-physicist\nNot every student who needs to understand a given phenomenon has the luxury of spending a course (or even multiple courses) learning the requisite material to engage with it from a first principles perspective. As an example, polarimetric analysis of RADAR data is becoming an increasingly important method in the remote sensing of climate systems. However it is unreasonable to require environmental studies students to take an electromagnetism course and a Fourier analysis course simply to engage with one class of practical methods6. Once concrete learning goals have been identified, sims can allow students to investigate precisely the aspects of a phenomenon that is relevant, skipping unnecessary formalism. Moreover sims can offer a more engaging, less intimidating environment to students unsure of their ability (33). Sims can also allow students to develop a nascent familiarity in less time than simple recitation (3).\n\nUltimately the appeal of sims then becomes the ability to personally investigate well thought out representations of physical phenomena, rather than rely on either alienatingly dense theoretical descriptions or high-level but disjointed characterizations.\n\n\n\n\nThe Limitations and Pitfalls of implementing sims\n\n or: OK, but let’s walk back that excitement\nRutten et al.’s broad 2012 review of sim implementation concluded that while significant effort has been placed on studying their design, far less research considers sim development as a holistic part of course development, taking into account curriculum goals, overall lesson structure, and the role of the instructor during simulation activities (3). Early meta analysis of computer simulation studies found that students struggle with creating hypotheses and designing new experiments when these activities are not intentionally supported in the instruction design (2); these results mirror similar conclusions from studies on physical experimentation, see e.g. studies on inquiry- vs. verification-based laboratory design (34–36). Since the emergence of these technologies in the late 1980s authors have argued that new media offers little or no intrinsic benefit to teaching and must be implemented with intention as a single tool in a broader pedagogical paradigm; see e.g. Salomon’s critique (37), Dillenbourg’s criticism and suggested methods of computer-integrated learning (38), or the conclusions of Schittek et al.’s meta analysis in the context of medical instruction (39).\nThis can perhaps be seen as an extension of the short-sighted tendency of educators to view instruction as the direct transfer of understanding to students authors have identified, see e.g. Wieman’s critique of conventional lecture-based instruction (40). Indeed in my own attempt to fold IM into my lectures, I was quickly enamored by the potential to finally come up with representations of phenomena which did justice to my own internal model, unrestricted by conventional media. Yet this obscures the point of teaching: to be of service to learners, to help them achieve their learning development and goals. The entire point of these tools remains to encourage students to form their own models, and to see the interchangeability and relative merits of ostensibly “competing” models. My own experience and the literature at large remind us to be careful and intentional when creating these tools, to ensure they exist to serve a specific purpose within the broader course design and that these tools don’t usurp our overall pedagogical strategy for a course.",
    "crumbs": [
      "Research",
      "Physics Pedagogy",
      "Interactive Simulations in Physics Education"
    ]
  },
  {
    "objectID": "research/pedagogy/CUT_research_paper.html#implementation-principles",
    "href": "research/pedagogy/CUT_research_paper.html#implementation-principles",
    "title": "Interactive Simulations in Physics Education",
    "section": "Implementation Principles",
    "text": "Implementation Principles\nSo how do we use sims effectively? We can identify common methods of in-class sim use, which may be comingled in a given implementation.\nInstructor-Lead\nInstructor-lead uses of sims are straightforward extensions of conventional lectures with an obvious eye towards allowing more active learning. In basic implementations the sim may simply be a visual aid depicting the phenomena being discussed, with the instructor manipulating the parameters and demonstrating outcomes as those concepts arise in the lecture script. Obviously however the instructor is free to merely act as a ‘gatekeeper’ for the sim, and supply the class with goals or hypotheses to achieved or tested. Typical methods of active discussion (e.g. paired students, small groups, discussion circles, anonymous submission, clickers) can then be used to encourage participation and elicit responses. Studies of student responses to sims commonly find that while sims are effective at conveying concept knowledge, this then leads students to more complex questions that requires the aid of a subject matter expert (27,41). Illustrative examples can be found in (19,24,42).\nGuided Inquiry\nIn guided inquiry, students are invited to explore a sim freely while pursuing a set of questions or outcomes to generate. Students may be asked to explain how the phenomena in question is dependent upon a particular parameter (e.g. (19,43)) or to seek a combination of inputs which produce a particular result (e.g. (42)). This is in obvious parallel to conventional laboratory design, and sims can be used outside of lecture in an analogous manner. However the convenience and responsiveness of simulations make them well-suited to guided inquiry within the classroom as well. After providing initial background instructors may ask students to actively investigate course concepts. When doing so, it is important to consider:\n1 - Care must be taken to provide instructions which are specific enough to align purposefully with learning goals, but are not so specific as to constrain student’s investigation of the simulated environment. Being overly prescriptive limits student’s ability to form their own goals and hypotheses (19).\n2 - Instructions and goals should be few and intentional, directly aligned with that lecture’s learning goals. Providing too many goals may limit student’s absorption of content and limit the amount of time available for thorough investigation (19).\n3 - Peer-to-peer instruction and discussion are useful to inquiry. Guided inquiry tasks with sims can be approached in small groups, and easily folded into existing strategies such as think-pair-share.\nSpecific examples of guided inquiry with sims in-class can be found in, e.g. (19,43–45).\nFree or Open Inquiry\nThe absence of guides is free inquiry, where students explore a simulated environment without externally-provided instruction or motivation. This method can be dangerous: it lacks inherent connection to learning goals, risks alienating or overwhelming students who feel intimidated by the content, and ultimately relies entirely on the sim design itself. In the related context of game-based learning, many authors have empirically shown the importance of ensuring the design guides learners to activities which are explicitly linked to desired cognitive processes 7. Guidance may help decrease cognitive load, induce reflection which learners may otherwise eschew, and decrease frustration or feelings of inability (27,33). In their analysis of physics sim design, Adams et al. noted that “exploration is not always productive” and suggested identifying and pruning any such avenues not aligned with primary learning goals (27)8. However some authors suggest free inquiry can be a useful way to have learners already capably familiar with other inquiry methods develop hypothesis-building and experimental design skills (26,47). In these cases regular discussion either in groups or with instructors is likely critical to encourage reflection and contextualize knowledge gained. Free inquiry must be carefully implemented: while free inquiry is sometimes romanticized as simulating what it is to “do real science”, taken to the extreme it may result in a deleterious condition known as “graduate studies”.\nThinking of sims as tools for conducting investigation, we can see these categories map well onto inquiry-based pedagogy classifications, see e.g. the Confirmation/Structured/Guided/Open inquiry hierarchy of (26) or the Confirmation/Structure/Guided/Open/Authentic hierarchy of (48). Ultimately, we must ask ourselves: is our use of sims supporting or usurping the learning goals? Are the desired learning processes actually being induced in students?",
    "crumbs": [
      "Research",
      "Physics Pedagogy",
      "Interactive Simulations in Physics Education"
    ]
  },
  {
    "objectID": "research/pedagogy/CUT_research_paper.html#design-principles",
    "href": "research/pedagogy/CUT_research_paper.html#design-principles",
    "title": "Interactive Simulations in Physics Education",
    "section": "Design Principles",
    "text": "Design Principles\nSims not developed intentionally as part of a broader collection or educational resource project often reflect the designer’s own perspective (or technical ability…). But what principles should guide us, if we want to add such a tool to our teaching?\nEncouraging Exploration\nAs discussed earlier, countless authors have examined and extolled the importance of exploration or discovery learning in physics education, see e.g. (13). Sims then need to be designed from the start to facilitate exploration and interrogation of the phenomena at hand. This puts an emphasis on interactivity and generality: sims should allow students to manipulate all relevant parameters easily and concoct any combination they deem worth observing. Sims can also be designed, or supplemented with written material, to create puzzles or leading inquiries for the student to fixate upon and solve (27). As we look at the following design principles, we will see how they support exploration.\nCredibility and Realism\nIf the goal is to get students to engage in active exploration, we need to construct sims that students think are worthwhile. The validity of the sim and its clear connection to student’s experience is then key: in a study of student’s responses to a quantum mechanics sim, learners were observed to take the activity less seriously and spend less time with it when instructors showed it produced erroneous results for a specific parameter combination (27). Evidently exploration becomes more frustrating when you can’t be confident that the representation is accurate. Similarly if the representation is not relevant, what’s the point? Students respond more enthusiastically to sims with representations of familiar, every-day objects and attempt to recreate responses they already expect in order to ‘test’ sims (49). Sims must be accurate and comprehensive (to their scope).\nFun!9\n“Users were disappointed that the temperature could reach thousands of degrees and the box remained intact, so we added a feature where the lid flies off under extreme conditions. Now users are more satisfied.” (49)\nExploration is more captivating when it’s, well, enjoyable. Students spend more time with and are more likely to engage deeply with sims they find at least somewhat enjoyable (41). Students are aware of how much learning they need to do to be successful in a competitive system: perhaps adding a little fun helps students feel more at-ease and be less self-critical. Fun can be a distraction however, essentially offering a different objective than actually interrogating the phenomenon. Care needs to be taken to remove sim elements that are “too fun” while not engendering any desired learning processes.\nStudent Interview and Input\nWhile following overarching pedagogical principles provides a reliable framework for creating useful tools, it is important to actively solicit student thoughts on each simulation. This provides empirical evidence about whether desired learning processes are occurring: in their study of sim design effects on student learning and attitude, PhET team researchers used multiple rounds of interview and redesign for 52 sims assessed by 89 non-science students, finding that:\n“These interviews always reveal interface weaknesses, resolve interface questions that were not agreed upon by the team, and often reveal pedagogically undesirable (and occasionally unexpected desirable) features and subtle programming bugs.” (27) [emphasis mine]\nAlthough the need to actually empirically investigate the effectiveness of a sim is obvious enough, the process of doing so requires much care and effort. First it is critical that the sampled students accurately represent the target population, whether in considering students of different educational backgrounds and previous academic performance or ensuring that a representative minimum of students belonging to marginalized groups are included. Moreover students should have little to no prior exposure to the particular material. The method of interview needs to monitor both the learning outcomes and processes. Thus authors have commonly observed students as they interact with the sim for the first time: think-aloud transcriptions (27) and directed questioning (50) are commonly used to probe student’s thoughts.\nBeyond this student input is particularly important in the context of universal design and ensuring equitable outcomes for learners. In their study of physics sim design, Adams et al. found that efficacy varied substantially with (27):\n1 - Student familiarity with the material\n2 - Student familiarity with the style of sim\n3 - Student’s own expectations of their understanding\n4 - Student’s perception of the sim as connected to their experience of the real world\nStudents became intimidated, self-conscious, or frustrated when simulations were too difficult to use. This then emphasizes intuitiveness and flexibility in sim design, to accommodate learners with different prior exposure to the material or user experience used. In their companion paper on UI design, Adams et al. identified click-and-drag, checkbox, slider, and grabbable interfaces as being most commonly understood, and the use of minimalism and intentional visual cues to prevent learners from feeling overwhelmed or lost (49). Moreover consistency in design and representation between sims was critical to make them intuitive and relate concepts between them.\nInterestingly students who had previously taken a course on a given topic were more likely to simply use sims as visual aids for their own explanations when not actively directed, then become self-conscious, self-critical, and switch from mastery orientation to performance orientation when faced with difficulty remembering concepts. This underscores our main point: students need to be engaged in active exploration for sims to be effective, and their response to and use of sims guided by the instructor.",
    "crumbs": [
      "Research",
      "Physics Pedagogy",
      "Interactive Simulations in Physics Education"
    ]
  },
  {
    "objectID": "research/pedagogy/CUT_research_paper.html#reflections-on-my-own-implementations",
    "href": "research/pedagogy/CUT_research_paper.html#reflections-on-my-own-implementations",
    "title": "Interactive Simulations in Physics Education",
    "section": "Reflections on my own implementations",
    "text": "Reflections on my own implementations\nIt’s straightforward enough, if time-consuming, to consult the literature. But seeing as the lesson learned has been that experimentation is key to learning, it would seem we need to design and introduce some sims ourselves to appreciate what works and what doesn’t. I wrote several simulations for my teaching of GEOG 371 - Advanced Remote Sensing in Fall 2023. GEOG 371 is an excellent test course to implement physics sims in – while it deals intimately with satellite-based instruments and the nature of electromagnetic radiation, it is ultimately concerned with practical applications to climate monitoring. Students are typically enrolled in environmental majors such as geomatics, geography/environmental management, and resources/sustainability and have relatively nascent physics training. Despite this they are expected to form a nontrivial understanding of notoriously confusing topics such as polarization state, phase, and various atmospheric light-matter interactions such as Rayleigh scatter.\nI sought to use sims to help teach three concepts which are typically not well understood by students in the course:\n1 - How waves sum (necessary to understand constructive and deconstructive interference)\n2 - Basic polarization states (necessary to understand RADAR imaging)\n3 - How speckle arises (necessary to interpret RADAR images)\nThe goal here is to efficiently get students to acquire an elementary intuitive understanding of these topics, and engage them in topics that students are often intimidated by. These sims differed in form and implementation while staying generally consistent with the principles outlined above: consistent representation, minimalism and reduced cognitive load, intuitive controls, fully general and bug-free. The simulations were used in-lecture using a guided approach: after outlining the basic theory in conventional lecture, I demonstrated the basic functionality of the sims to the class. Students were then given a short amount of time (1-2 minutes) to familiarize themselves with the sims individually, before pairing up with a partner to investigate a set of questions. After paired experimentation students were asked to voluntarily share their findings with the class; this process is analogous to and adapted from traditional think-pair-share activities(51).\nIntuitively I understood the appeal of the following design choices:\n1 - Minimalism and clarity of design to decrease cognitive load\n2 - Consistency of representation to prevent confusion and make connections between sims\n3 - Intuitive, fun10 controls over programmatically simpler options\nThe sum of waves sim took this form (linked to decrease load on this page). The polarization state sim took this form.\nThe speckle sim took the following form:\n\nCode\nchart = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    // define a bounding rectangle\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", height - 2*stroke_width)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 0.087124976) //This is a hard-coded value based on the prescribed physical parameters. It's hardcoded because it's easier than dealing with the resulting reactive dependencies since this cell should never be run again\n\n    // define data used for circles\n    const circles = d3.range(2).map(i =&gt; ({\n        x: (i+2) * width / 5,\n        y: (i+1) * height / 3,\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", d =&gt; d.x)\n            .attr(\"cy\", d =&gt; d.y)\n            .attr(\"r\", radius)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[d.index * 3])\n            .attr(\"id\", function(d,i) {return i})\n            .call(drag)\n\n    return svg.node();\n}\nchart2 = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    //define a function to take the canvas position of the leftside chart to the\n    //  corresponding region in the second chart\n    //  it's messy because I solved the system by hand and didn't simplify, RIP\n    //  to future Jake if I ever have to un-hardcode the object position values\n    function lineartransform(xposition){\n        return (2*height/5 - radius)/(5/7*width -2*radius-2)*xposition + width/7 + 2/5*height + radius/2 - (2*height/5 - radius)*(width/7+radius+1)/(5/7*width-2*radius-2)\n    }\n\n    // define a earth curvature line\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", height - 2*stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", stroke_width/2)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 0)\n\n    // define lines going from the target to the satellites (first, so they appear under them)\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 3*height/20)\n        .attr(\"x2\", lineartransform(x1))\n        .attr(\"y1\", 3*height/20)\n        .attr(\"y2\", height - 2*stroke_width)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"blue\")\n\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 3*height/20)\n        .attr(\"x2\", lineartransform(x2))\n        .attr(\"y1\", 3*height/20)\n        .attr(\"y2\", height - 2*stroke_width)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"red\")\n\n\n    // define a rectangle representing the satellite\n    svg.append(\"rect\")\n        .attr(\"x\", width/7 + height/10)\n        .attr(\"y\", height/10)\n        .attr(\"width\", height/10)\n        .attr(\"height\", height/10)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", .50)\n    \n    // define notches indicating the bounds of the pixel\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 2*height/5)\n        .attr(\"x2\", width/7 + 2*height/5)\n        .attr(\"y1\", height - 2*stroke_width)\n        .attr(\"y2\", height - 2*stroke_width - height/20)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"black\")\n\n    svg.append(\"line\")\n        .attr(\"x1\", width/7 + 4*height/5)\n        .attr(\"x2\", width/7 + 4*height/5)\n        .attr(\"y1\", height - 2*stroke_width)\n        .attr(\"y2\", height - 2*stroke_width - height/20)\n        .style(\"stroke-width\", stroke_width)\n        .style(\"stroke\", \"black\")\n\n    // define data used for circles\n    const circles = d3.range(2).map(i =&gt; ({\n        x: (i+2) * width / 5,\n        y: (i+1) * height / 3,\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", function(d,i) {\n                if (i == 0) {return lineartransform(x1)}\n                else {return lineartransform(x2)}\n            })\n            .attr(\"cy\", height - 2*stroke_width)\n            .attr(\"r\", radius/2)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[d.index * 3])\n            .attr(\"id\", function(d,i) {return i})\n\n    // add text\n    svg.append(\"text\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", .94*height)\n        .style(\"font-size\", \"28px\")\n        .text(\"side view\")\n\n    svg.append(\"text\")\n        .attr(\"x\", width/2)\n        .attr(\"y\", .15*height)\n        .style(\"font-size\", \"24px\")\n        .style(\"font-style\", \"italic\")\n        .text(\"*wildly not to scale\")\n\n    return svg.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nformatted_d1 = (0.5*distance_travelled_w1).toFixed(2).replace(/\\B(?&lt;!\\.\\d*)(?=(\\d{3})+(?!\\d))/g, \",\");\nformatted_d2 = (0.5*distance_travelled_w2).toFixed(2).replace(/\\B(?&lt;!\\.\\d*)(?=(\\d{3})+(?!\\d))/g, \",\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistance from target one to the satellite: m\nDistance from target two to the satellite: m\n\n\n\nCode\n// defines how circles change appearance and position in response to cursor drag\ndrag = {\n\n    // move the circles to cursor position when dragging is active\n    function dragged(event, d){\n        var newx = event.x;\n        if (newx &lt; xbounds[0]) newx = xbounds[0];\n        if (newx &gt; xbounds[1]) newx = xbounds[1];\n        var newy = event.y;\n        if (newy &lt; ybounds[0]) newy = ybounds[0];\n        if (newy &gt; ybounds[1]) newy = ybounds[1];\n        \n        if (d3.select(this).attr('id') == \"0\") {\n            mutable x1 = newx;\n            mutable y1 = newy;\n        }\n        if (d3.select(this).attr('id') == \"1\") {\n            mutable x2 = newx;\n            mutable y2 = newy;\n        }\n        \n        d3.select(this).raise().attr(\"cx\", d.x = newx).attr(\"cy\", d.y = newy);\n\n        var dt1 = 2*Math.sqrt(sat_z**2 + (mutable x1/width*pixel_width - sat_x)**2 + (mutable y1/width*pixel_width - sat_y)**2);\n        var dt2 = 2*Math.sqrt(sat_z**2 + (mutable x2/width*pixel_width - sat_x)**2 + (mutable y2/width*pixel_width - sat_y)**2);\n        var p1  =  dt1 / wavelength *2 *Math.PI;\n        var p2  =  dt2 / wavelength *2 *Math.PI;\n\n        d3.select(\"rect\").attr(\"fill-opacity\", 1-Math.abs(Math.cos((p1-p2)/2)));\n        //d3.select(\"text\").text(1-Math.abs(Math.cos((p1-p2)/2))).style(\"fill\",\"darkOrange\");\n    }\n\n    // map the d3 drag event functionality to these custom functions\n    return d3.drag()\n        .on(\"drag\", dragged)\n}\n\n\n\n\n\n\n\n\n\nCode\nmutable x1= 2*width/5;\nmutable y1= height/3;\nmutable x2= 3*width/5;\nmutable y2= 2*height/3;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nstroke_width = 7;\nwidth = 700;\nheight = 500 + 2*stroke_width;\nradius = 25;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nxbounds = [width/7 + radius + 1, 6*width/7 - radius - 1]\nybounds = [ radius + 1  + stroke_width, height - radius - 1 - stroke_width]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndistance_sp = 4;\nNumPoints = 1000;\nwavelength = .5;\namplitude = 15;\nspeed = 10;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n// display variables\nxscale_factor = 100;\n\n\n\n\n\n\n\n\n\nCode\nsat_x = -100000;\nsat_y = 100000;\nsat_z = 600000;\npixel_width = 3;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndistance_travelled_w1 = 2*Math.sqrt(sat_z**2 + (x1/width*pixel_width - sat_x)**2 + (y1/width*pixel_width - sat_y)**2);\ndistance_travelled_w2 = 2*Math.sqrt(sat_z**2 + (x2/width*pixel_width - sat_x)**2 + (y2/width*pixel_width - sat_y)**2);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nphase_w1 = distance_travelled_w1 / wavelength *2 *Math.PI;\nphase_w2 = distance_travelled_w2 / wavelength *2 *Math.PI;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwave1 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance_sp / NumPoints;\n        data.push([j*xscale_factor, amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w2)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwave2 = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance_sp / NumPoints;\n        data.push([j*xscale_factor , amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w1)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nwaveSum = {\n    var data = [];\n    for (var i = 1; i &lt;= NumPoints; i++) {\n        var j = i * distance_sp / NumPoints;\n        data.push([j*xscale_factor , amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w1) + amplitude * Math.sin(j * 2*Math.PI / wavelength + time + phase_w2)]);\n    }\n    return data;\n}\n\n\n\n\n\n\n\n\n\nCode\nr_sp = d3.line()(wave1);\nb_sp = d3.line()(wave2);\nsvg`&lt;svg viewBox=\"0 -32 400 64\"&gt;\n  &lt;path d=\"${r_sp}\" stroke=\"red\" fill=\"none\" /&gt;\n  &lt;path d=\"${b_sp}\" stroke=\"blue\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np_sp = d3.line()(waveSum);\nsvg`&lt;svg viewBox=\"0 -64 400 130\"&gt;\n  &lt;path d=\"${p_sp}\" stroke=\"black\" fill=\"none\" /&gt;\n&lt;/svg&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nd3 = require(\"d3@7\")\n\n\n\n\n\n\n\nIt depicts a RADAR satellite 600km above the Earth, showing how the relative placement of reflectors in a scene can cause the returned waves to constructively or deconstructively interfere on return, making the pixel bright or dark. A detailed explanation can be found here but is not necessary for this discussion. The partner section below extends the concept to the statistical level, generating the output of many random configurations.\n\n\nCode\ntargetnum_1 = 10;\ntargetnum_2 = 10;\nmax_radius_p1 = 35;\nmin_radius_p1 = 25;\nmax_radius_p2 = 20;\nmin_radius_p2 = 15;\n\nradii_p1 = {\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_1; i++) {\n            data.push(Math.random()*(max_radius_p1-min_radius_p1) + min_radius_p1);\n        }\n    return data;\n}\n\nradii_p2 = {\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_2; i++) {\n            data.push(Math.random()*(max_radius_p2-min_radius_p2) + min_radius_p2);\n        }\n    return data;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof reroll_toggle = Inputs.form(\n    [\n        Inputs.button(\"Redistribute Targets\"),\n        Inputs.button(\"Auto Redistribute Targets\"),\n    ],\n    {\n        template: (inputs) =&gt; htl.html`&lt;div style=\"display: flex; gap: 1em\"&gt;\n        ${inputs}\n        &lt;/div&gt;`\n    })\n\nvtoggle1    = reroll_toggle[0];\nauto_toggle = reroll_toggle[1];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntime_auto = {\n  let i = 0;\n  while (auto_toggle%2==1) {\n    i += 1;\n    yield i\n  }\n}\n\n\n\n\n\n\n\n\n\nCode\npixel1_positions = {\n    var dummy  = vtoggle1;\n    var dummy2 = time_auto;\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_1; i++) {\n            var x = Math.random()*(5*width/7 - 2*max_radius_p1) + max_radius_p1 + width/7;\n            var y = Math.random()*(height - 2*max_radius_p1) + max_radius_p1;\n            data.push([x,y]);\n        }\n    return data\n}\n\npixel2_positions = {\n    var dummy  = vtoggle1;\n    var dummy2 = time_auto;\n    var data = [];\n        for (var i = 1; i &lt;= targetnum_2; i++) {\n            var x = Math.random()*(5*width/7 - 2*max_radius_p1) + max_radius_p1 + width/7;\n            var y = Math.random()*(height - 2*max_radius_p1) + max_radius_p1;\n            data.push([x,y]);\n        }\n    return data\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n//two pixels with targets in them\n\nchart3 = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    // define a bounding rectangle\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", height - 2*stroke_width)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 1-amplitude_p1/200)\n\n    // define data used for circles\n    const circles = d3.range(targetnum_1).map(i =&gt; ({\n        x: pixel1_positions[i][0],\n        y: pixel1_positions[i][1],\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", d =&gt; d.x)\n            .attr(\"cy\", d =&gt; d.y)\n            .attr(\"r\", function(d,i) {return radii_p1[i]})\n            .attr(\"stroke\", \"black\")\n            .attr(\"stroke-width\", 4)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[0])\n            .attr(\"id\", function(d,i) {return i})\n\n    return svg.node();\n}\nchart4 = {\n    const svg = d3.create(\"svg\").attr(\"viewBox\", [0, 0, width, height])\n\n    // define a bounding rectangle\n    svg.append(\"rect\")\n        .attr(\"x\", width/7)\n        .attr(\"y\", stroke_width)\n        .attr(\"width\", 5*width/7)\n        .attr(\"height\", height - 2*stroke_width)\n        .attr(\"stroke\", \"black\")\n        .attr(\"stroke-width\", stroke_width)\n        .attr(\"fill-opacity\", 1-amplitude_p2/200)\n\n    // define data used for circles\n    const circles = d3.range(targetnum_2).map(i =&gt; ({\n        x: pixel2_positions[i][0],\n        y: pixel2_positions[i][1],\n        index: i, \n    }));\n\n    // define circles as graphic objects\n    svg.selectAll(\"circle\")\n        .data(circles)\n        .join(\"circle\")\n            .attr(\"cx\", d =&gt; d.x)\n            .attr(\"cy\", d =&gt; d.y)\n            .attr(\"r\", function(d,i) {return radii_p2[i]})\n            .attr(\"stroke\", \"black\")\n            .attr(\"stroke-width\", 4)\n            .attr(\"fill\", d =&gt; d3.schemeCategory10[0])\n            .attr(\"id\", function(d,i) {return i})\n\n    return svg.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n    round: true,\n    color: {legend: true},\n    x: {label: \"Brightness\"},\n    y: {label: \"Frequency\"},\n    marks: [\n        Plot.rectY(brightnesses, Plot.binX({y2: \"count\"}, {x: \"x\", fill: \"p\", mixBlendMode: \"multiply\"})),\n        Plot.ruleY([0])\n        ]\n})\n\n\n\n\n\n\n\n\n\nCode\namplitude_p1 = {\n\n    var dummy = vtoggle1;\n    \n    var amplitude_naught = radii_p1[0];\n\n    var dt_naught =\n        2*Math.sqrt(\n            sat_z**2\n            + (pixel1_positions[0][0]/width*pixel_width - sat_x)**2\n            + (pixel1_positions[0][1]/width*pixel_width - sat_y)**2\n        );\n    \n    var phase_naught =\n        dt_naught / wavelength *2 *Math.PI;\n    \n    //successively add the waves, determining the new phases and amplitudes\n    for (var i = 1; i &lt;= targetnum_1-1; i++) {\n        //compute the phase of the next subwave\n        var dt_next =\n            2*Math.sqrt(\n                sat_z**2\n                + (pixel1_positions[i][0]/width*pixel_width - sat_x)**2\n                + (pixel1_positions[i][1]/width*pixel_width - sat_y)**2\n        );\n\n        var phase_next = \n            dt_next / wavelength *2 *Math.PI;\n        \n        //compute the amplitude of the new sum\n        var new_amplitude =\n            Math.sqrt(\n                amplitude_naught**2\n                + radii_p1[i]**2\n                + 2*amplitude_naught*radii_p1[i]*Math.cos(phase_next-phase_naught)\n            );\n\n        //compute the phase of the new sum\n        var new_phase =\n            Math.atan(\n                (amplitude_naught*Math.sin(phase_naught) + radii_p1[i]*Math.sin(phase_next))\n                /(amplitude_naught*Math.cos(phase_naught) + radii_p1[i]*Math.cos(phase_next))\n            )\n\n        amplitude_naught = new_amplitude;\n        phase_naught = new_phase;\n\n    }\n    return amplitude_naught\n}\n\namplitude_p2 = {\n\n    var dummy = vtoggle1;\n    \n    var amplitude_naught = radii_p2[0];\n\n    var dt_naught =\n        2*Math.sqrt(\n            sat_z**2\n            + (pixel2_positions[0][0]/width*pixel_width - sat_x)**2\n            + (pixel2_positions[0][1]/width*pixel_width - sat_y)**2\n        );\n    \n    var phase_naught =\n        dt_naught / wavelength *2 *Math.PI;\n    \n    //successively add the waves, determining the new phases and amplitudes\n    for (var i = 1; i &lt;= targetnum_1-1; i++) {\n        //compute the phase of the next subwave\n        var dt_next =\n            2*Math.sqrt(\n                sat_z**2\n                + (pixel2_positions[i][0]/width*pixel_width - sat_x)**2\n                + (pixel2_positions[i][1]/width*pixel_width - sat_y)**2\n        );\n\n        var phase_next = \n            dt_next / wavelength *2 *Math.PI;\n        \n        //compute the amplitude of the new sum\n        var new_amplitude =\n            Math.sqrt(\n                amplitude_naught**2\n                + radii_p2[i]**2\n                + 2*amplitude_naught*radii_p2[i]*Math.cos(phase_next-phase_naught)\n            );\n\n        //compute the phase of the new sum\n        var new_phase =\n            Math.atan(\n                (amplitude_naught*Math.sin(phase_naught) + radii_p2[i]*Math.sin(phase_next))\n                /(amplitude_naught*Math.cos(phase_naught) + radii_p2[i]*Math.cos(phase_next))\n            )\n\n        amplitude_naught = new_amplitude;\n        phase_naught = new_phase;\n\n    }\n    return amplitude_naught\n}\n\n{\nmutable brightnesses.push({x: amplitude_p1, p: \"Pixel 1\"});\nmutable brightnesses.push({x: amplitude_p2, p: \"Pixel 2\"});\nmutable brightnesses = mutable brightnesses;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n//histogram to be populated with the brightness values of the two pixels\nmutable brightnesses = [];\n\n\n\n\n\n\n\nThese simulations were generally well-received, though to what extent this was simply due to them being interesting diversions from lecture is unclear. Due to the nature of the course and limited resources, comprehensive student interview or response testing was not conducted beyond a majority of students indicating they ‘enjoyed’ the sims. Given the goal of producing certain outcomes or hypothesizing about the effects of certain changes, several student pairs shared ideas commensurate with the level of understanding needed to apply the concepts to the course material.\nUltimately however, as discussed above we would need to measurably tie the use of these sims to the achievement of learning goals, and incorporate student feedback cyclically, to be confident about their merits as teaching tools. Their creation itself has instead become my own learning experience, and perhaps a useful free resource for anyone desperate enough to find themselves on page 3+ of Google search.",
    "crumbs": [
      "Research",
      "Physics Pedagogy",
      "Interactive Simulations in Physics Education"
    ]
  },
  {
    "objectID": "research/pedagogy/CUT_research_paper.html#conclusion",
    "href": "research/pedagogy/CUT_research_paper.html#conclusion",
    "title": "Interactive Simulations in Physics Education",
    "section": "Conclusion",
    "text": "Conclusion\nSims offer students a uniquely valuable opportunity to engage in active, personalized exploration of phenomena in an efficient and engaging way. They allow students to interrogate relationships directly, form and test hypotheses, and interact with representations too complex for chalk and board. Moreover they can offer students a less intimidating exposure to concepts which they have little foreknowledge of. However sims are only effective when designed and implemented with consideration of broader pedagogical principles. The following are the most salient in both my review of the literature and own experience:\n1 - Sims should be designed to facilitate engaged exploration of phenomena\n2 - Sims must be empirically evaluated by monitoring the experiences of learners and ensuring they align directly with learning goals\n3 - Guidance is needed to ensure sim use is productive and encourage reflection on the results of student’s experiments\nThe difficulty of creating good sims (requiring programming, subject matter, and pedagogical expertise) can make their development and use sparse, limited only to large collections with staff and testing procedures, e.g. PHeT. Worse it can make their use superficial or misguided. Yet when intentionally developed as part of a larger educational program, their effect on engagement and learning is too substantial to dismiss.\n\n\nCode\ntime = {\n  let i = 0;\n  while (true) {\n    i += 0.1;\n    yield i\n  }\n}",
    "crumbs": [
      "Research",
      "Physics Pedagogy",
      "Interactive Simulations in Physics Education"
    ]
  },
  {
    "objectID": "research/pedagogy/CUT_research_paper.html#footnotes",
    "href": "research/pedagogy/CUT_research_paper.html#footnotes",
    "title": "Interactive Simulations in Physics Education",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee, e.g. (19)↩︎\nSee, e.g. (20)↩︎\nSee, e.g. (21)↩︎\nLikely with less neat handiwork!↩︎\nWhile this may seem like a somewhat trivial improvement, anyone who has dealt with interpreting more advanced wave properties like polarization state may see the value added here↩︎\nAlbeit extremely cool and interesting methods, studied by extremely cool and interesting, yet modest and well-adjusted, people who are fun at parties↩︎\nSee table 38.2 in Handbook of Research on Educational Communications and Technology (46)↩︎\nConsider for example the principle of error tolerance in universal design↩︎\nʸᶦᵖᵖᵉᵉ !↩︎\nand haaaaard to program…↩︎",
    "crumbs": [
      "Research",
      "Physics Pedagogy",
      "Interactive Simulations in Physics Education"
    ]
  }
]